
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Airbnb Data Challenge}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}380}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          \PY{k+kn}{import} \PY{n+nn}{sklearn}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
          \PY{k+kn}{import} \PY{n+nn}{datetime} \PY{k}{as} \PY{n+nn}{dt}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k}{import} \PY{n}{LinearRegression}\PY{p}{,} \PY{n}{Ridge}\PY{p}{,} \PY{n}{LogisticRegression}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
          \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{svm}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import} \PY{n}{GaussianNB}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{metrics}
          \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{preprocessing}
          \PY{k+kn}{import} \PY{n+nn}{keras}
          \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
          \PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{display.max\PYZus{}columns}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{k+kc}{None}\PY{p}{)}
          \PY{k+kn}{import} \PY{n+nn}{datetime} \PY{k}{as} \PY{n+nn}{dt}
          \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
          
          
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{Tokenizer}
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{preprocessing}\PY{n+nn}{.}\PY{n+nn}{sequence} \PY{k}{import} \PY{n}{pad\PYZus{}sequences}
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Input}\PY{p}{,} \PY{n}{LSTM}\PY{p}{,} \PY{n}{Embedding}\PY{p}{,} \PY{n}{Dropout}\PY{p}{,} \PY{n}{Activation}\PY{p}{,} \PY{n}{Conv1D}\PY{p}{,} \PY{n}{Flatten}
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Bidirectional}\PY{p}{,} \PY{n}{GlobalMaxPool1D}\PY{p}{,} \PY{n}{MaxPooling1D}
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Model}\PY{p}{,} \PY{n}{Sequential}
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{callbacks} \PY{k}{import} \PY{n}{EarlyStopping}\PY{p}{,} \PY{n}{History}
          \PY{k+kn}{from} \PY{n+nn}{keras} \PY{k}{import} \PY{n}{initializers}\PY{p}{,} \PY{n}{regularizers}\PY{p}{,} \PY{n}{constraints}\PY{p}{,} \PY{n}{optimizers}\PY{p}{,} \PY{n}{layers}
          \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{optimizers} \PY{k}{import} \PY{n}{SGD}\PY{p}{,} \PY{n}{Adam}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{GridSearchCV}
\end{Verbatim}


    \section{Problem Overview}\label{problem-overview}

In this data challenge, I will use Airbnb data to predict whether a user
will request a booking or not 30 days into the future. The dataset
provided here contains a random sample of listings from three markets,
San Francisco, Paris and Los Angeles.

(Note: This paragraph is direclty from Prompt) Each row in the dataset
is a combination of a listing and a calendar night for which we try to
predict if it will be booked, based on what we know 30 days prior to the
calendar night.The calendar night is denotedby ds\_night and ranges
between 2015-01-01 and 2015-12-31. All the data in the dataset, except
for column dim\_is\_requested, is current for 30 days beforeds\_night,
denoted by ds (i.e., ds + 30 days = ds\_night).

\texttt{dim\_is\_requested} refers to whether or not the listing was
ultimately requested a booking for theds\_night. Listing, ds\_night
combinations that were already booked or are otherwise unavailable 30
days prior willnot appear in the dataset

    \section{Reading Data}\label{reading-data}

Let's start by reading the data and looking at some quick statistics to
get a sense of the volume and magnitude of the data we are dealing with.
From the data we can see that there are a few kinds of features:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Price: price of listing on a given night
\item
  Listing attributes: such as exact location, size,reviews, decor, etc;
\item
  Occupancy and availability of the listing: these features are
  calculated looking at the status of the calendar.
\item
  Demand for alisting: based on clicks and views
\item
  Demand and supply within a KDT-Room type cluster: from a machine
  learning algorithm to cluster the listings that are close
  geographically, as an automated way to identify neighborhoods.gs.
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}381}]:} \PY{n}{airbnb\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TH\PYZus{}data\PYZus{}challenge.tsv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}381}]:}    dim\_is\_requested    ds\_night          ds  \textbackslash{}
          0             False  2015-01-06  2014-12-07   
          1              True  2015-01-21  2014-12-22   
          2             False  2015-01-22  2014-12-23   
          3              True  2015-02-02  2015-01-03   
          4              True  2015-02-13  2015-01-14   
          
                                  id\_listing\_anon                          id\_user\_anon  \textbackslash{}
          0  0ae0c7cc-a8a4-425f-9ccc-8b25dbb94f4d  dcc74708-d5c4-47b2-bc0c-97bf5abfcd99   
          1  82fdda07-6993-4cca-8ee4-fc218d2c07c7  559d8981-0c75-4631-9582-a3b644bb5631   
          2  69b2069d-cf8f-49a7-b559-9619dbe86a7d  ee7901a6-79d5-4d69-bacf-e4bca976a66a   
          3  66baade6-9352-4d7c-b590-745899bd12b3  af691f3d-525e-497c-b9c5-8750b097b04d   
          4  01e3589e-a50a-494b-8cb2-9645b29476d0  6733a1d9-d485-4ea7-b8d2-883ee8a363b9   
          
             m\_effective\_daily\_price  m\_pricing\_cleaning\_fee   dim\_market    dim\_lat  \textbackslash{}
          0               110.000000                    60.0  Los Angeles  34.053932   
          1                70.000000                     0.0  Los Angeles  34.108578   
          2               125.000000                     0.0  Los Angeles  34.077194   
          3               126.866667                   125.0  Los Angeles  34.093494   
          4               210.714286                   200.0  Los Angeles  34.097540   
          
                dim\_lng    dim\_room\_type  dim\_person\_capacity  dim\_is\_instant\_bookable  \textbackslash{}
          0 -118.362970     Private room                    2                    False   
          1 -118.208600     Private room                    2                     True   
          2 -118.205700     Private room                    1                    False   
          3 -118.247340  Entire home/apt                    6                    False   
          4 -118.363556  Entire home/apt                    5                    False   
          
             m\_checkouts  m\_reviews  days\_since\_last\_booking  cancel\_policy  \textbackslash{}
          0         24.0       19.0                    320.0              4   
          1        105.0       55.0                      3.0              3   
          2          0.0        0.0                      NaN              3   
          3          0.0        0.0                      NaN              5   
          4          9.0        1.0                     34.0              5   
          
             image\_quality\_score  m\_total\_overall\_rating  m\_professional\_pictures  \textbackslash{}
          0             0.830959                    74.0                     16.0   
          1             0.967384                   263.0                      0.0   
          2             0.485231                     0.0                      0.0   
          3             0.309310                     0.0                      0.0   
          4             0.335816                     5.0                      0.0   
          
             dim\_has\_wireless\_internet  ds\_night\_day\_of\_week  ds\_night\_day\_of\_year  \textbackslash{}
          0                          1                     2                     6   
          1                          1                     3                    21   
          2                          1                     4                    22   
          3                          1                     1                    33   
          4                          1                     5                    44   
          
             ds\_checkin\_gap  ds\_checkout\_gap  occ\_occupancy\_plus\_minus\_7\_ds\_night  \textbackslash{}
          0             0.0              7.0                                  NaN   
          1             7.0              7.0                                  NaN   
          2             7.0              7.0                                  NaN   
          3             7.0              7.0                                  0.0   
          4             7.0              7.0                                  0.0   
          
             occ\_occupancy\_plus\_minus\_14\_ds\_night  occ\_occupancy\_trailing\_90\_ds  \textbackslash{}
          0                                   NaN                      0.000000   
          1                                   NaN                      0.359551   
          2                                   NaN                      0.000000   
          3                                   0.0                      0.000000   
          4                                   0.0                      0.133333   
          
             m\_minimum\_nights  m\_maximum\_nights  price\_booked\_most\_recent  \textbackslash{}
          0               5.0              90.0                      92.0   
          1               1.0            1125.0                      70.0   
          2               1.0            1125.0                       NaN   
          3               3.0            1125.0                       NaN   
          4               2.0            1125.0                     296.0   
          
             p2\_p3\_click\_through\_score  p3\_inquiry\_score  \textbackslash{}
          0                        NaN               NaN   
          1                        NaN               NaN   
          2                        NaN               NaN   
          3                        NaN               NaN   
          4                        NaN               NaN   
          
             listing\_m\_listing\_views\_2\_6\_ds\_night\_decay  \textbackslash{}
          0                                    0.133333   
          1                                    0.066667   
          2                                    0.000000   
          3                                    0.733333   
          4                                    1.000000   
          
             general\_market\_m\_unique\_searchers\_0\_6\_ds\_night  \textbackslash{}
          0                                      788.142857   
          1                                      830.142857   
          2                                      810.142857   
          3                                      816.857143   
          4                                     1347.428571   
          
             general\_market\_m\_contacts\_0\_6\_ds\_night  \textbackslash{}
          0                              241.428571   
          1                              298.000000   
          2                              281.000000   
          3                              274.428571   
          4                              419.428571   
          
             general\_market\_m\_reservation\_requests\_0\_6\_ds\_night  \textbackslash{}
          0                                          41.428571    
          1                                          51.714286    
          2                                          51.714286    
          3                                          41.857143    
          4                                          78.857143    
          
             general\_market\_m\_is\_booked\_0\_6\_ds\_night  m\_available\_listings\_ds\_night  \textbackslash{}
          0                                      1.0                           9840   
          1                                      1.0                           9599   
          2                                      1.0                           9514   
          3                                      1.0                           9739   
          4                                      1.0                           9114   
          
             kdt\_score  r\_kdt\_listing\_views\_0\_6\_avg\_n100  r\_kdt\_n\_active\_n100  \textbackslash{}
          0   1.314286                          1.795918                 57.0   
          1   0.535714                          2.693878                 49.0   
          2   0.714286                          2.775510                 49.0   
          3   1.744681                          4.576531                113.0   
          4   1.200000                          4.877551                 97.0   
          
             r\_kdt\_n\_available\_n100  r\_kdt\_m\_effective\_daily\_price\_n100\_p50  \textbackslash{}
          0                    48.0                                    79.0   
          1                    36.0                                    65.0   
          2                    35.0                                    65.0   
          3                    52.0                                   120.0   
          4                    57.0                                   150.0   
          
             r\_kdt\_m\_effective\_daily\_price\_available\_n100\_p50  \textbackslash{}
          0                                              75.0   
          1                                              65.0   
          2                                              66.5   
          3                                             115.0   
          4                                             157.5   
          
             r\_kdt\_m\_effective\_daily\_price\_booked\_n100\_p50  
          0                                           98.0  
          1                                           42.0  
          2                                           46.0  
          3                                          115.0  
          4                                          164.5  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}382}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of rows are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of columns are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of unique listings are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{nunique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of unique users are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}user\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{nunique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of calendar days in the data are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{nunique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The number of rows are: 184279
The number of columns are: 46
The number of unique listings are: 10442
The number of unique users are: 7936
The number of calendar days in the data are: 364

    \end{Verbatim}

    The distribution of the predicted feature (whether a listing will be
booked or not on a given day 30 days in the future is shown below. From
the distribution, it can be seen that the 2 classes Not Booked vs Booked
are distributed approximately 66\% vs 33\% with 33\% of listings ending
up booked on a given day 30 days into the future (Flagged as 1).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}383}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
AxesSubplot(0.125,0.125;0.775x0.755)

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_6_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Looking at the distribution of the predictor features below we can see
that almost all features are on different scales and have very different
distributions. This means I will be doing scaling before training
models.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}384}]:} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}384}]:}        dim\_is\_requested  m\_effective\_daily\_price  m\_pricing\_cleaning\_fee  \textbackslash{}
          count     184279.000000            184279.000000           184279.000000   
          mean           0.328361               149.405456               38.014286   
          std            0.469618               272.233310               49.998184   
          min            0.000000               -55.000000                0.000000   
          25\%            0.000000                71.349427                0.000000   
          50\%            0.000000               100.000000               25.000000   
          75\%            1.000000               152.346733               53.947735   
          max            1.000000             12995.000000              800.000000   
          
                       dim\_lat        dim\_lng  dim\_person\_capacity    m\_checkouts  \textbackslash{}
          count  184279.000000  184279.000000        184279.000000  184092.000000   
          mean       43.551959     -44.277191             3.265234      18.461883   
          std         6.817239      59.187486             2.009478      32.309469   
          min        33.708763    -122.510925             1.000000       0.000000   
          25\%        34.129663    -118.357056             2.000000       1.000000   
          50\%        48.844982       2.303334             2.000000       6.000000   
          75\%        48.871037       2.355681             4.000000      22.000000   
          max        49.187890       2.887966            16.000000     432.000000   
          
                     m\_reviews  days\_since\_last\_booking  cancel\_policy  \textbackslash{}
          count  184092.000000            146443.000000  184279.000000   
          mean       10.971194                69.174136       4.154109   
          std        20.020473               123.530963       0.816571   
          min         0.000000                 0.000000       3.000000   
          25\%         0.000000                 5.000000       3.000000   
          50\%         3.000000                20.000000       4.000000   
          75\%        12.000000                72.000000       5.000000   
          max       280.000000              1041.000000       8.000000   
          
                 image\_quality\_score  m\_total\_overall\_rating  m\_professional\_pictures  \textbackslash{}
          count        170268.000000           184092.000000            184092.000000   
          mean              0.562056               47.881706                 4.795211   
          std               0.306840               86.908863                 8.503853   
          min               0.000000                0.000000                 0.000000   
          25\%               0.300549                0.000000                 0.000000   
          50\%               0.577958               14.000000                 0.000000   
          75\%               0.853520               54.000000                10.000000   
          max               0.999996             1313.000000                80.000000   
          
                 dim\_has\_wireless\_internet  ds\_night\_day\_of\_week  ds\_night\_day\_of\_year  \textbackslash{}
          count              184279.000000         184279.000000         184279.000000   
          mean                    0.937741              2.998763            174.657953   
          std                     0.241626              2.004867            108.087953   
          min                     0.000000              0.000000              1.000000   
          25\%                     1.000000              1.000000             77.000000   
          50\%                     1.000000              3.000000            171.000000   
          75\%                     1.000000              5.000000            267.000000   
          max                     1.000000              6.000000            364.000000   
          
                 ds\_checkin\_gap  ds\_checkout\_gap  occ\_occupancy\_plus\_minus\_7\_ds\_night  \textbackslash{}
          count   182058.000000    182058.000000                        163552.000000   
          mean         5.888091         6.123241                             0.061373   
          std          2.197909         2.041068                             0.159816   
          min          0.000000         0.000000                             0.000000   
          25\%          7.000000         7.000000                             0.000000   
          50\%          7.000000         7.000000                             0.000000   
          75\%          7.000000         7.000000                             0.000000   
          max          7.000000         7.000000                             1.000000   
          
                 occ\_occupancy\_plus\_minus\_14\_ds\_night  occ\_occupancy\_trailing\_90\_ds  \textbackslash{}
          count                         163627.000000                 174061.000000   
          mean                               0.079742                      0.280268   
          std                                0.171301                      0.311951   
          min                                0.000000                      0.000000   
          25\%                                0.000000                      0.000000   
          50\%                                0.000000                      0.148148   
          75\%                                0.068966                      0.530612   
          max                                1.000000                      1.000000   
          
                 m\_minimum\_nights  m\_maximum\_nights  price\_booked\_most\_recent  \textbackslash{}
          count     182058.000000      1.820580e+05             146443.000000   
          mean           4.998753      4.782557e+04                140.255458   
          std           22.389882      1.006587e+07                159.847870   
          min            1.000000      1.000000e+00                  0.000000   
          25\%            1.000000      3.000000e+01                 69.000000   
          50\%            2.000000      1.125000e+03                100.000000   
          75\%            3.000000      1.125000e+03                155.000000   
          max         1000.000000      2.147484e+09               4999.000000   
          
                 p2\_p3\_click\_through\_score  p3\_inquiry\_score  \textbackslash{}
          count               57169.000000      54989.000000   
          mean                    0.231738          0.180926   
          std                     0.073645          0.073416   
          min                     0.052968          0.013492   
          25\%                     0.181564          0.128333   
          50\%                     0.223077          0.171852   
          75\%                     0.270523          0.223158   
          max                     0.766491          0.643529   
          
                 listing\_m\_listing\_views\_2\_6\_ds\_night\_decay  \textbackslash{}
          count                               181933.000000   
          mean                                     0.385088   
          std                                      1.032900   
          min                                      0.000000   
          25\%                                      0.000000   
          50\%                                      0.000000   
          75\%                                      0.333333   
          max                                     36.133333   
          
                 general\_market\_m\_unique\_searchers\_0\_6\_ds\_night  \textbackslash{}
          count                                   184279.000000   
          mean                                      1702.574448   
          std                                        686.574394   
          min                                        316.714286   
          25\%                                       1194.285714   
          50\%                                       1629.857143   
          75\%                                       2175.428571   
          max                                       3696.714286   
          
                 general\_market\_m\_contacts\_0\_6\_ds\_night  \textbackslash{}
          count                           184279.000000   
          mean                               507.456627   
          std                                255.179472   
          min                                 52.000000   
          25\%                                349.714286   
          50\%                                488.000000   
          75\%                                619.285714   
          max                               1453.857143   
          
                 general\_market\_m\_reservation\_requests\_0\_6\_ds\_night  \textbackslash{}
          count                                      184279.000000    
          mean                                           91.624327    
          std                                            48.652866    
          min                                            13.142857    
          25\%                                            56.000000    
          50\%                                            83.142857    
          75\%                                           116.714286    
          max                                           271.571429    
          
                 general\_market\_m\_is\_booked\_0\_6\_ds\_night  m\_available\_listings\_ds\_night  \textbackslash{}
          count                            184279.000000                  184279.000000   
          mean                                  0.973079                   18551.170611   
          std                                   0.071519                    9099.781958   
          min                                   0.571429                    1028.000000   
          25\%                                   1.000000                    9690.000000   
          50\%                                   1.000000                   21027.000000   
          75\%                                   1.000000                   24867.000000   
          max                                   1.000000                   37892.000000   
          
                     kdt\_score  r\_kdt\_listing\_views\_0\_6\_avg\_n100  r\_kdt\_n\_active\_n100  \textbackslash{}
          count  184279.000000                     184278.000000        184278.000000   
          mean        1.067703                          2.098260            90.208587   
          std         0.523330                          2.081157            75.792493   
          min        -1.000000                          0.000000             1.000000   
          25\%         0.666667                          0.857143            48.000000   
          50\%         1.037037                          1.632653            86.000000   
          75\%         1.396552                          2.717687           113.000000   
          max         3.000000                         45.081633           910.000000   
          
                 r\_kdt\_n\_available\_n100  r\_kdt\_m\_effective\_daily\_price\_n100\_p50  \textbackslash{}
          count           184278.000000                           184278.000000   
          mean                45.636869                              109.231766   
          std                 37.506994                               64.013523   
          min                  0.000000                                0.000000   
          25\%                 25.000000                               75.000000   
          50\%                 41.000000                               95.259429   
          75\%                 56.000000                              129.000000   
          max                483.000000                             1374.500000   
          
                 r\_kdt\_m\_effective\_daily\_price\_available\_n100\_p50  \textbackslash{}
          count                                     184262.000000   
          mean                                         115.385867   
          std                                           72.728042   
          min                                            0.000000   
          25\%                                           77.728465   
          50\%                                           98.538890   
          75\%                                          135.474918   
          max                                         1500.000000   
          
                 r\_kdt\_m\_effective\_daily\_price\_booked\_n100\_p50  
          count                                  171304.000000  
          mean                                       95.601191  
          std                                        48.744252  
          min                                         0.000000  
          25\%                                        65.000000  
          50\%                                        86.079324  
          75\%                                       115.754137  
          max                                      1995.000000  
\end{Verbatim}
            
    Now let's sort the data by listing id and dates to see if there are any
gaps in the data. From the sorted data below we can see that there are
indeed some dates for which there is no data for a listing date
combination. From the prompt we know that listing, ds\_night
combinations that were already booked or are otherwise unavailable 30
days prior will not appear in the dataset. Therefore, we can assume that
these days are missing because of either of the two reasons. We will use
this implicit knowledge to also derive features later on.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}385}]:} \PY{n}{airbnb\PYZus{}data} \PY{o}{=} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}385}]:}         dim\_is\_requested    ds\_night          ds  \textbackslash{}
          92617                  0  2015-01-03  2014-12-04   
          45319                  0  2015-01-04  2014-12-05   
          4394                   0  2015-01-07  2014-12-08   
          177135                 0  2015-01-13  2014-12-14   
          43123                  0  2015-01-14  2014-12-15   
          
                                       id\_listing\_anon  \textbackslash{}
          92617   00004783-f5e1-47cf-90bf-3daad76d1a09   
          45319   00004783-f5e1-47cf-90bf-3daad76d1a09   
          4394    00004783-f5e1-47cf-90bf-3daad76d1a09   
          177135  00004783-f5e1-47cf-90bf-3daad76d1a09   
          43123   00004783-f5e1-47cf-90bf-3daad76d1a09   
          
                                          id\_user\_anon  m\_effective\_daily\_price  \textbackslash{}
          92617   251917ad-d2e8-467d-ace3-7e5699e16b89               308.737257   
          45319   251917ad-d2e8-467d-ace3-7e5699e16b89               308.386883   
          4394    251917ad-d2e8-467d-ace3-7e5699e16b89               307.170580   
          177135  251917ad-d2e8-467d-ace3-7e5699e16b89               311.518725   
          43123   251917ad-d2e8-467d-ace3-7e5699e16b89               311.522589   
          
                  m\_pricing\_cleaning\_fee dim\_market   dim\_lat   dim\_lng  \textbackslash{}
          92617                85.950775      Paris  48.87363  2.312445   
          45319                85.809113      Paris  48.87363  2.312445   
          4394                 85.542191      Paris  48.87363  2.312445   
          177135               85.266556      Paris  48.87363  2.312445   
          43123                85.177414      Paris  48.87363  2.312445   
          
                    dim\_room\_type  dim\_person\_capacity  dim\_is\_instant\_bookable  \textbackslash{}
          92617   Entire home/apt                    3                    False   
          45319   Entire home/apt                    3                    False   
          4394    Entire home/apt                    3                    False   
          177135  Entire home/apt                    3                    False   
          43123   Entire home/apt                    3                    False   
          
                  m\_checkouts  m\_reviews  days\_since\_last\_booking  cancel\_policy  \textbackslash{}
          92617           0.0        0.0                      NaN              3   
          45319           0.0        0.0                      NaN              3   
          4394            0.0        0.0                      NaN              3   
          177135          0.0        0.0                      NaN              3   
          43123           0.0        0.0                      NaN              3   
          
                  image\_quality\_score  m\_total\_overall\_rating  m\_professional\_pictures  \textbackslash{}
          92617              0.095232                     0.0                      0.0   
          45319              0.095232                     0.0                      0.0   
          4394               0.095232                     0.0                      0.0   
          177135             0.095232                     0.0                      0.0   
          43123              0.095232                     0.0                      0.0   
          
                  dim\_has\_wireless\_internet  ds\_night\_day\_of\_week  ds\_night\_day\_of\_year  \textbackslash{}
          92617                           1                     6                     3   
          45319                           1                     0                     4   
          4394                            1                     3                     7   
          177135                          1                     2                    13   
          43123                           1                     3                    14   
          
                  ds\_checkin\_gap  ds\_checkout\_gap  occ\_occupancy\_plus\_minus\_7\_ds\_night  \textbackslash{}
          92617              7.0              7.0                                  NaN   
          45319              7.0              7.0                                  NaN   
          4394               7.0              7.0                                  NaN   
          177135             7.0              7.0                                  NaN   
          43123              7.0              7.0                                  NaN   
          
                  occ\_occupancy\_plus\_minus\_14\_ds\_night  occ\_occupancy\_trailing\_90\_ds  \textbackslash{}
          92617                                    NaN                           0.0   
          45319                                    NaN                           0.0   
          4394                                     NaN                           0.0   
          177135                                   NaN                           0.0   
          43123                                    NaN                           0.0   
          
                  m\_minimum\_nights  m\_maximum\_nights  price\_booked\_most\_recent  \textbackslash{}
          92617                1.0            1125.0                       NaN   
          45319                1.0            1125.0                       NaN   
          4394                 1.0            1125.0                       NaN   
          177135               1.0            1125.0                       NaN   
          43123                1.0            1125.0                       NaN   
          
                  p2\_p3\_click\_through\_score  p3\_inquiry\_score  \textbackslash{}
          92617                         NaN               NaN   
          45319                         NaN               NaN   
          4394                          NaN               NaN   
          177135                        NaN               NaN   
          43123                         NaN               NaN   
          
                  listing\_m\_listing\_views\_2\_6\_ds\_night\_decay  \textbackslash{}
          92617                                     0.000000   
          45319                                     0.000000   
          4394                                      0.733333   
          177135                                    0.000000   
          43123                                     0.000000   
          
                  general\_market\_m\_unique\_searchers\_0\_6\_ds\_night  \textbackslash{}
          92617                                      1673.857143   
          45319                                      1288.428571   
          4394                                       1162.428571   
          177135                                     1104.714286   
          43123                                      1118.285714   
          
                  general\_market\_m\_contacts\_0\_6\_ds\_night  \textbackslash{}
          92617                               782.571429   
          45319                               563.000000   
          4394                                440.285714   
          177135                              418.142857   
          43123                               419.285714   
          
                  general\_market\_m\_reservation\_requests\_0\_6\_ds\_night  \textbackslash{}
          92617                                          144.142857    
          45319                                          102.714286    
          4394                                            76.428571    
          177135                                          62.571429    
          43123                                           62.000000    
          
                  general\_market\_m\_is\_booked\_0\_6\_ds\_night  \textbackslash{}
          92617                                       1.0   
          45319                                       1.0   
          4394                                        1.0   
          177135                                      1.0   
          43123                                       1.0   
          
                  m\_available\_listings\_ds\_night  kdt\_score  \textbackslash{}
          92617                           19373   0.863636   
          45319                           19654   0.727273   
          4394                            20774   0.863636   
          177135                          21457   0.454545   
          43123                           21513   0.727273   
          
                  r\_kdt\_listing\_views\_0\_6\_avg\_n100  r\_kdt\_n\_active\_n100  \textbackslash{}
          92617                           3.532653                124.0   
          45319                           2.262585                123.0   
          4394                            1.938776                122.0   
          177135                          2.367347                122.0   
          43123                           2.151020                123.0   
          
                  r\_kdt\_n\_available\_n100  r\_kdt\_m\_effective\_daily\_price\_n100\_p50  \textbackslash{}
          92617                     61.0                              166.718119   
          45319                     61.0                              160.361179   
          4394                      66.0                              159.728702   
          177135                    72.0                              160.743662   
          43123                     73.0                              158.253475   
          
                  r\_kdt\_m\_effective\_daily\_price\_available\_n100\_p50  \textbackslash{}
          92617                                         194.504472   
          45319                                         185.032130   
          4394                                          165.872113   
          177135                                        186.911235   
          43123                                         171.337424   
          
                  r\_kdt\_m\_effective\_daily\_price\_booked\_n100\_p50  
          92617                                      135.844393  
          45319                                      132.606360  
          4394                                       135.155055  
          177135                                     111.523704  
          43123                                      112.148132  
\end{Verbatim}
            
    \section{PART A - Data Preprocessing}\label{part-a---data-preprocessing}

\subsection{a) Handling Missing Values}\label{a-handling-missing-values}

Before I can start training my model, I have to process the data so that
it can be fed into a machine learning algorithm. Let's check to see
which features have missing data.

Important Note: Some algorithms like Linear Regression can be very
sensitive to outliers in the data. Other algos like Tree Methods (and
Log Regression) are not sensitive to large outliers but for Linear
Regressions it can make a difference in performance. Since this is a
binary classification problem and linear regression will not be used I
will skip capping outliers as it's unlikely to lead to a big change in
performance here.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}386}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Lets check for missing values in the data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}name, number of nulls}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{k}{for} \PY{n}{feature} \PY{o+ow}{in} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
              \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{feature}\PY{p}{)} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{n}{feature}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Lets check for missing values in the data

feature\_name, number of nulls
dim\_is\_requested,0
ds\_night,0
ds,0
id\_listing\_anon,0
id\_user\_anon,0
m\_effective\_daily\_price,0
m\_pricing\_cleaning\_fee,0
dim\_market,0
dim\_lat,0
dim\_lng,0
dim\_room\_type,0
dim\_person\_capacity,0
dim\_is\_instant\_bookable,0
m\_checkouts,187
m\_reviews,187
days\_since\_last\_booking,37836
cancel\_policy,0
image\_quality\_score,14011
m\_total\_overall\_rating,187
m\_professional\_pictures,187
dim\_has\_wireless\_internet,0
ds\_night\_day\_of\_week,0
ds\_night\_day\_of\_year,0
ds\_checkin\_gap,2221
ds\_checkout\_gap,2221
occ\_occupancy\_plus\_minus\_7\_ds\_night,20727
occ\_occupancy\_plus\_minus\_14\_ds\_night,20652
occ\_occupancy\_trailing\_90\_ds,10218
m\_minimum\_nights,2221
m\_maximum\_nights,2221
price\_booked\_most\_recent,37836
p2\_p3\_click\_through\_score,127110
p3\_inquiry\_score,129290
listing\_m\_listing\_views\_2\_6\_ds\_night\_decay,2346
general\_market\_m\_unique\_searchers\_0\_6\_ds\_night,0
general\_market\_m\_contacts\_0\_6\_ds\_night,0
general\_market\_m\_reservation\_requests\_0\_6\_ds\_night,0
general\_market\_m\_is\_booked\_0\_6\_ds\_night,0
m\_available\_listings\_ds\_night,0
kdt\_score,0
r\_kdt\_listing\_views\_0\_6\_avg\_n100,1
r\_kdt\_n\_active\_n100,1
r\_kdt\_n\_available\_n100,1
r\_kdt\_m\_effective\_daily\_price\_n100\_p50,1
r\_kdt\_m\_effective\_daily\_price\_available\_n100\_p50,17
r\_kdt\_m\_effective\_daily\_price\_booked\_n100\_p50,12975

    \end{Verbatim}

    We can see that a lot of features have null values. Some of these make a
lot of sense if a listing never had a booking in the past. For example,
"days\_since\_last\_booking" will be null for listings with no bookings
in the past. Similarly if a listing just launched, we might not have
data going back 7 or 14 days so features like
occ\_occupancy\_plus\_minus\_14\_ds\_night will not have any data.

For these features which make intuitive sense we can just hardcode
missing values to a unique number never seen before (example: -1). For
other features like "m\_checkouts", and "m\_reviews", since the number
of missing rows is so small (187 records). we can just drop them from
the dataset as 187 rows is unlikely to make a big difference in
performance.

Finally some other features like 'image quality score' and
'p2\_p3\_click\_through\_score' seem to be missing values for some
users. We could use the mean value for the KDT node for these values to
replace the missing values with. (Note: The key assumption being here
that these features are fairly "static" features in nature so taking a
mean across the entire dataset won't result in any leakage from the
future.). Although for now we will just hard code to unseen -1 value for
missing data.

Because of time constraints, the missing values are being imputed.
However if I had more time (and data) I would actually build separate
predictive models to predict the missing values (for example: predict
click through score).

\subsection{b) Checking distributions of Some Features with Missing
Data}\label{b-checking-distributions-of-some-features-with-missing-data}

Also, double checking to see if there is anything else that is funky
about these features that have a lot of missing data. Most seem to have
a healthy distribution count so we can try to assume that the missing
values are not necessarily due to complete garbage data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}387}]:} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}minimum\PYZus{}nights}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}387}]:} array([[<matplotlib.axes.\_subplots.AxesSubplot object at 0x1a7f88198>]],
                dtype=object)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_14_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}388}]:} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p3\PYZus{}inquiry\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}388}]:} array([[<matplotlib.axes.\_subplots.AxesSubplot object at 0x1a38689b0>]],
                dtype=object)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}389}]:} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{image\PYZus{}quality\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bins} \PY{o}{=}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}389}]:} array([[<matplotlib.axes.\_subplots.AxesSubplot object at 0x1770f0c18>]],
                dtype=object)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}390}]:} \PY{k}{def} \PY{n+nf}{clean\PYZus{}data}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
              
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{days\PYZus{}since\PYZus{}last\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{days\PYZus{}since\PYZus{}last\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}7\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}7\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}14\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}14\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}trailing\PYZus{}90\PYZus{}ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}trailing\PYZus{}90\PYZus{}ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}minimum\PYZus{}nights}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}minimum\PYZus{}nights}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}maximum\PYZus{}nights}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}maximum\PYZus{}nights}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds\PYZus{}checkin\PYZus{}gap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds\PYZus{}checkin\PYZus{}gap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds\PYZus{}checkout\PYZus{}gap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds\PYZus{}checkout\PYZus{}gap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}booked\PYZus{}most\PYZus{}recent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}booked\PYZus{}most\PYZus{}recent}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
              
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p2\PYZus{}p3\PYZus{}click\PYZus{}through\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p2\PYZus{}p3\PYZus{}click\PYZus{}through\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p3\PYZus{}inquiry\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p3\PYZus{}inquiry\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}m\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZus{}booked\PYZus{}n100\PYZus{}p50}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p3\PYZus{}inquiry\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{image\PYZus{}quality\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{image\PYZus{}quality\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
          
              \PY{n}{data}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
              \PY{k}{return} \PY{n}{data}
           
          \PY{n}{airbnb\PYZus{}data} \PY{o}{=} \PY{n}{clean\PYZus{}data}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{)}
\end{Verbatim}


    Using the above function , it now looks like the missing values are all
gone and our data has been cleaned!

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}391}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Now}\PY{l+s+s1}{\PYZsq{}} \PY{n}{Lets} \PY{n}{check} \PY{k}{for} \PY{n}{missing} \PY{n}{values} \PY{o+ow}{in} \PY{n}{the} \PY{n}{data}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}name, number of nulls}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{k}{for} \PY{n}{feature} \PY{o+ow}{in} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
              \PY{n+nb}{print}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{feature}\PY{p}{)} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{n}{feature}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

          File "<ipython-input-391-4ddc3ff5ab5a>", line 1
        print('Now' Lets check for missing values in the data')
                       \^{}
    SyntaxError: invalid syntax


    \end{Verbatim}

    \subsection{c) Converting Categorical Features to Dummy
Variables}\label{c-converting-categorical-features-to-dummy-variables}

Most of the features are numeric in this dataset but a couple are
categorical (dim\_is\_instant\_bookable, dim\_market, dim\_room\_type).
These will be one hot encoded to a binary category for each class so
they can be fed into the algorithm

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{} Convert categorical features to dummy variables using one hot encoding}
        \PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}instant\PYZus{}bookable}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}instant\PYZus{}bookable}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{int64}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{categorical\PYZus{}columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}market}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{one\PYZus{}hot\PYZus{}encoded\PYZus{}columns} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{n}{categorical\PYZus{}columns}\PY{p}{]}\PY{p}{,} \PY{n}{drop\PYZus{}first}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{airbnb\PYZus{}data} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{airbnb\PYZus{}data}\PY{p}{,} \PY{n}{one\PYZus{}hot\PYZus{}encoded\PYZus{}columns}\PY{p}{]}\PY{p}{,} \PY{n}{axis} \PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{columns\PYZus{}to\PYZus{}drop} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}market}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}room\PYZus{}type}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns} \PY{o}{=} \PY{n}{columns\PYZus{}to\PYZus{}drop}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \section{PART B - Train, Validation and Test
Splitting}\label{part-b---train-validation-and-test-splitting}

Now that we have cleaned the data, the next step is to create train,
validation and test splits which can be used to train and evaluate the
models we will build. Since the data is time series centric with an
element of seasonality, and we only have a full year's worth of data the
cutoff for train and test will be done randomly. By doing a random split
we ensure both train and test have some component from each week of the
year so they can fully understand seasonality in bookings. Second,
looking at the time distribution of records below we can see that there
is a peak in December but otherwise each month has a reasonable amount
of records so we do not risk missing some time periods if we random
sampled.

However, if we had more than year's worth of data (let's say 2 whole
years), then it might be better to split train and test by year. For
example train in 2016 and test in 2017. This helps in generalizing and
preventing overfitting to highly local and unique trends that might
occur one year but not the other. (Example: Let's say there is a once in
a lifetime concert in New York that only occured in June 2017 and led to
a surge in bookings for that month year only)

Test was split in a 30\% ratio. The remaining 70\% were further split in
a 70/30\% ratio into train and validation. So approiximately 50\% of the
data was train. 20\% was validation. 30\% was Test.

All features were also normalized using mean-std scaling

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Histogram of Records by Date}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{split\PYZus{}perc}\PY{p}{)}\PY{p}{:}
            
            \PY{c+c1}{\PYZsh{}train\PYZus{}valid = data[data[\PYZsq{}ds\PYZsq{}] \PYZlt{}= date\PYZus{}cutoff]}
            \PY{c+c1}{\PYZsh{}test = data[data[\PYZsq{}ds\PYZsq{}] \PYZgt{} date\PYZus{}cutoff] }
            
            \PY{n}{standard\PYZus{}scaler} \PY{o}{=} \PY{n}{preprocessing}\PY{o}{.}\PY{n}{StandardScaler}\PY{p}{(}\PY{n}{with\PYZus{}mean}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{with\PYZus{}std}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
            
            \PY{n}{train\PYZus{}valid}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{split\PYZus{}perc}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{45}\PY{p}{)}
            \PY{n}{train}\PY{p}{,} \PY{n}{valid} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{train\PYZus{}valid}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{split\PYZus{}perc}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{45}\PY{p}{)}
            
            \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
            \PY{n}{x\PYZus{}valid} \PY{o}{=} \PY{n}{valid}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
            \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
            
            \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
            \PY{n}{x\PYZus{}valid} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
            \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
            
            \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
            \PY{n}{y\PYZus{}valid} \PY{o}{=} \PY{n}{valid}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
            \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
                
            \PY{k}{return} \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test}
        
        \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of records and columns in train are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of records and columns in validation are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The number of records and columns in test are: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \section{PART C - Baseline Creation}\label{part-c---baseline-creation}

For the baseline, we will simply take the booking status of the last
period for which we have data for that listing prior to the'ds' or the
calendar date. So for example if the ds = '2014-12-15' and we are
predicting for '2015-01-14' then the baseline will take the last
bookings status of the period prior to '2015-12-15'.

For example, if there is data for '2015-12-14' then we will use the
booking status for that day as our prediction for ds = '2015-12-15'. If
not, then we will keep going back until there is data for that listing
from a date. For days for which we do not have any prior historical
data, we simply predict 0.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}396}]:} \PY{c+c1}{\PYZsh{}baseline\PYZus{}prob = bookings\PYZus{}last\PYZus{}day(airbnb\PYZus{}data[\PYZsq{}dim\PYZus{}is\PYZus{}requested\PYZsq{}], 1) }
          \PY{n}{baseline\PYZus{}prob} \PY{o}{=} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
          \PY{n}{baseline\PYZus{}prob} \PY{o}{=} \PY{n}{baseline\PYZus{}prob}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


    \subsection{Selection of Evaluation
Metric}\label{selection-of-evaluation-metric}

Now that we have a baseline, we need to decide on how to evaluate the
performance of different models or approaches. Since this is a binary
classification problem it makes most sense to use either Accuracy or AUC
for evaluation. Accuracy is a good measure because it is intuitive froma
a business perspective but is useless when classes are extremely
imbalanced. However, in this data classes are not imbalanced completely.
A 66\% ratio ensures that accuracy won't be 'gamed' by just predicting
the majority class.

For this reason the primary metric for evaluation will be Accuracy.
However, I will also look at Precision and Recall just to make sure we
aren't extremely biased towards/against one type of performance (or
errror). Precision is simply the percentage of records predicted to be
positive (booked) were actually positive. Recall is the \% of all
positive records (booked) in the dataset that we were able to predict
correcly. Mathematically:

Precision = Recall =

Based on that the baseline performance is as follows. For any machine
learning model to be considered useful it will have to beat the baseline
accuracy of 81.8\% while also ensuring precision and recall increase (or
at the very least don't worsen) compared tot he 74.2\% and 68.4\%
benchmarks. Ideally, by at least a few percentage points so it justifies
the added time and space complexity from a business standpoint.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}398}]:} \PY{k}{def} \PY{n+nf}{get\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{predictions}\PY{p}{,} \PY{n}{true\PYZus{}values}\PY{p}{)}\PY{p}{:}
              \PY{n}{accuracy} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{true\PYZus{}values}\PY{p}{,} \PY{n}{predictions}\PY{p}{)}
              \PY{n}{precision} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{precision\PYZus{}score}\PY{p}{(}\PY{n}{true\PYZus{}values}\PY{p}{,} \PY{n}{predictions}\PY{p}{)}
              \PY{n}{recall} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{recall\PYZus{}score}\PY{p}{(}\PY{n}{true\PYZus{}values}\PY{p}{,} \PY{n}{predictions}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{accuracy}\PY{p}{,} \PY{n}{precision}\PY{p}{,} \PY{n}{recall}
          
          \PY{n}{baseline\PYZus{}accuracy}\PY{p}{,} \PY{n}{baseline\PYZus{}precision}\PY{p}{,} \PY{n}{baseline\PYZus{}recall} \PY{o}{=} \PY{n}{get\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{baseline\PYZus{}prob}\PY{p}{,} \PY{n}{airbnb\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Baseline Accuracy is: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{baseline\PYZus{}accuracy}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Baseline Precision is: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{baseline\PYZus{}precision}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Baseline Recall is: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{baseline\PYZus{}recall}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The Baseline Accuracy is: 0.818
The Baseline Precision is: 0.742
The Baseline Recall is: 0.684

    \end{Verbatim}

    \section{PART D - Model Training and Parameter
Tuning}\label{part-d---model-training-and-parameter-tuning}

Now that we are done with data preprocessing I will first build simple
Machine Learning Models on train data to see how much performance I can
get without any feature engineering and if it beats the naive baseline
we had above. I will try a series of different models and each model
will be evaluated against the validation set to measure performance.
Each of these models will also be tuned on their key hyper parameters.

The choices for the algorithms are: 1) Logisitic Regression with
Regularization 2) Random Forest 3) Neural Networks (Later on)

Other good choices would include Support Vector Machines and Gradient
Boosting Machines which for now were ignored because of limited time
constraints (4-8 hours). (But not because I thought they did not have
potential to be good models)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}130}]:} \PY{k}{def} \PY{n+nf}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{alpha}\PY{p}{,} \PY{n}{penalty}\PY{p}{)}\PY{p}{:}
              \PY{n}{log\PYZus{}reg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{penalty}\PY{o}{=}\PY{n}{penalty}\PY{p}{,} \PY{n}{tol}\PY{o}{=}\PY{l+m+mf}{0.0001}\PY{p}{,} \PY{n}{C}\PY{o}{=}\PY{n}{alpha}\PY{p}{)}
              \PY{n}{log\PYZus{}reg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
              \PY{n}{preds} \PY{o}{=} \PY{n}{log\PYZus{}reg}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
              \PY{k}{return} \PY{n}{log\PYZus{}reg}\PY{p}{,} \PY{n}{preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}
          
          \PY{k}{def} \PY{n+nf}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{n\PYZus{}trees}\PY{p}{,} \PY{n}{min\PYZus{}leaf}\PY{p}{)}\PY{p}{:}
              \PY{n}{random\PYZus{}forest} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{n}{n\PYZus{}trees}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{min\PYZus{}samples\PYZus{}split}\PY{o}{=}\PY{l+m+mi}{2}
                                                     \PY{p}{,} \PY{n}{min\PYZus{}samples\PYZus{}leaf}\PY{o}{=}\PY{n}{min\PYZus{}leaf}\PY{p}{,} \PY{n}{verbose} \PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
              \PY{n}{random\PYZus{}forest}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
              \PY{n}{preds} \PY{o}{=} \PY{n}{random\PYZus{}forest}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
              \PY{k}{return} \PY{n}{random\PYZus{}forest}\PY{p}{,} \PY{n}{preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}
          
          \PY{k}{def} \PY{n+nf}{train\PYZus{}support\PYZus{}vector\PYZus{}machine}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{alpha}\PY{p}{)}\PY{p}{:}
              \PY{n}{svm\PYZus{}model} \PY{o}{=} \PY{n}{svm}\PY{o}{.}\PY{n}{SVC}\PY{p}{(}\PY{n}{C}\PY{o}{=}\PY{n}{alpha}\PY{p}{,} \PY{n}{kernel} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{probability}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{tol} \PY{o}{=} \PY{l+m+mf}{0.001}\PY{p}{,} \PY{n}{verbose} \PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
              \PY{n}{svm\PYZus{}model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
              \PY{n}{preds} \PY{o}{=} \PY{n}{svm\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
              \PY{k}{return} \PY{n}{svm\PYZus{}model}\PY{p}{,} \PY{n}{preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}
              
          \PY{k}{def} \PY{n+nf}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{preds}\PY{p}{,} \PY{n}{true}\PY{p}{,} \PY{n}{cutoff}\PY{p}{,} \PY{n}{verbose}\PY{p}{)}\PY{p}{:}
              \PY{n}{preds}\PY{p}{[}\PY{n}{preds} \PY{o}{\PYZgt{}}\PY{o}{=} \PY{n}{cutoff}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1}
              \PY{n}{preds}\PY{p}{[}\PY{n}{preds} \PY{o}{\PYZlt{}} \PY{n}{cutoff}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0}
              \PY{n}{acc}\PY{p}{,} \PY{n}{precision}\PY{p}{,} \PY{n}{recall} \PY{o}{=} \PY{n}{get\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{preds}\PY{p}{,} \PY{n}{true}\PY{p}{)}
              
              \PY{k}{if} \PY{n}{verbose} \PY{o}{==} \PY{k+kc}{True}\PY{p}{:}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The out of sample performance on validation data is:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The accuracy is }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{acc}\PY{p}{)}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The precision is }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{precision}\PY{p}{)}\PY{p}{)}
                  \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The recall is }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{recall}\PY{p}{)}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{acc}\PY{p}{,} \PY{n}{precision}\PY{p}{,} \PY{n}{recall}
\end{Verbatim}


    \subsection{a) Logistic Regression}\label{a-logistic-regression}

First I look at how a simple logistic regression performs with
regularization. Note: for log regression especially it is absolutely
critical that we scale all features prior to training. Fortunately this
was already done above while building the train and validation data sets
so I do not have to do it again. Second, it is generally a good idea to
remove highly correlated features for regressions. If more time had been
permitted I would have looked at correlations to do feature selection.
In this case however, i will use regualarization to help with
generalization and reduce overfitting at the expense of careful feature
selection.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}101}]:} \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{log\PYZus{}acc}\PY{p}{,} \PY{n}{log\PYZus{}pre}\PY{p}{,} \PY{n}{log\PYZus{}re} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The out of sample performance on validation data is:
The accuracy is 0.772
The precision is 0.704
The recall is 0.527

    \end{Verbatim}

    One of the key parameters for Log Regression with regularization is the
regularization strength. Increasing the strength can lead to better
generalizationa and less overfitting. Second, choosing the type of
regularization L1 vs L2 can also work better or worse on some datasets.
L1 is also good for working with highly correlated predictor features as
it helps shrink the feature space effectively setting unimportant
feature weights to 0. I will therefore do a grid search on different
regularization alphas (strength) and also the penalty itself to see
which parameters give the best performance on validation.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}108}]:} \PY{n}{lambda\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.0001}\PY{p}{,} \PY{l+m+mf}{0.0001}\PY{p}{,} \PY{l+m+mf}{0.001}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{]}
          \PY{n}{penalty} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          \PY{n}{log\PYZus{}grid\PYZus{}search\PYZus{}results} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model\PYZus{}Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Lambda}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Penalty}\PY{l+s+s1}{\PYZsq{}}
                                                          \PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid Accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid Precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid Recall}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{i} \PY{o}{=} \PY{l+m+mi}{0}
          \PY{k}{for} \PY{n}{p} \PY{o+ow}{in} \PY{n}{penalty}\PY{p}{:}
              \PY{k}{for} \PY{n}{l} \PY{o+ow}{in} \PY{n}{lambda\PYZus{}list}\PY{p}{:}
                  \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{l}\PY{p}{,} \PY{n}{p}\PY{p}{)}
                  \PY{n}{acc}\PY{p}{,} \PY{n}{pre}\PY{p}{,} \PY{n}{re} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{False}\PY{p}{)}
                  \PY{n}{log\PYZus{}grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n+nb}{len}\PY{p}{(}\PY{n}{log\PYZus{}grid\PYZus{}search\PYZus{}results}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{n}{l}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{acc}\PY{p}{,}\PY{n}{pre}\PY{p}{,}\PY{n}{re}\PY{p}{]}
                  \PY{n}{i} \PY{o}{=} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{log\PYZus{}grid\PYZus{}search\PYZus{}results}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
   Model\_Number  Lambda Penalty  Valid Accuracy  Valid Precision  Valid Recall
0             0  0.0001      l2        0.749534         0.671900      0.462309
1             1  0.0001      l2        0.749534         0.671900      0.462309
2             2  0.0010      l2        0.759261         0.701721      0.463018
3             3  0.0100      l2        0.769454         0.708564      0.504968
4             4  0.0500      l2        0.771264         0.704909      0.520817
5             5  0.1000      l2        0.771420         0.703967      0.523340
6             6  0.0001      l1        0.678601         0.816176      0.026258
7             7  0.0001      l1        0.678601         0.816176      0.026258
8             8  0.0010      l1        0.752225         0.720580      0.399779
9             9  0.0100      l1        0.770566         0.708566      0.510724
10           10  0.0500      l1        0.772196         0.705558      0.524523
11           11  0.1000      l1        0.771885         0.704272      0.525233

    \end{Verbatim}

    From the above it can be seen that the validation performance as
measured by accuracy, precision and recall is maximized for either L2 or
L1 penalty with a regularization strength of 0.1. Going forward that is
the strength I will be using for Log regression.

    \subsection{b) Random Forests}\label{b-random-forests}

Next, I will look to see if Random Forests can perform better than the
best logistic regression model. I also see if changing the minimum size
of the leaf node can help with better out of sample validation
performance. The results show that the smaller the min leaf size at each
leaf node then the better the out of sample performance but with minimal
gain less than a size 2. For this reason I will keep the min leaf size
of the random forest leaf nodes to be 2.

Since random forests reduce error by decreasing variance by building
many decision trees and averaging or voting on predictions, they tend to
perform better than individual decision trees. In this case the Random
Forest Model also performs much better than the Logistic Regression
Model although with comparable performance along the Baseline. Therefore
the simple model does okay so far.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}132}]:} \PY{n}{rf\PYZus{}results} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model\PYZus{}Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Trees}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Min Leaf Size}\PY{l+s+s1}{\PYZsq{}}
                                                          \PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid Accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid Precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid Recall}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          
          \PY{n}{i} \PY{o}{=} \PY{l+m+mi}{0}
          \PY{n}{leaf\PYZus{}sizes} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{]}
          \PY{k}{for} \PY{n}{l} \PY{o+ow}{in} \PY{n}{leaf\PYZus{}sizes}\PY{p}{:}
              \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{25}\PY{p}{,} \PY{n}{l}\PY{p}{)}
              \PY{n}{acc}\PY{p}{,} \PY{n}{pre}\PY{p}{,} \PY{n}{re} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{False}\PY{p}{)}
              \PY{n}{rf\PYZus{}results}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n+nb}{len}\PY{p}{(}\PY{n}{rf\PYZus{}results}\PY{p}{)}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{l+m+mi}{50}\PY{p}{,}\PY{n}{l}\PY{p}{,}\PY{n}{acc}\PY{p}{,}\PY{n}{pre}\PY{p}{,}\PY{n}{re}\PY{p}{]}
              \PY{n}{i} \PY{o}{=} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{rf\PYZus{}results}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
   Model\_Number  Trees  Min Leaf Size  Valid Accuracy  Valid Precision  \textbackslash{}
0           0.0   50.0            1.0        0.807326         0.711560   
1           1.0   50.0            2.0        0.808645         0.720043   
2           2.0   50.0            5.0        0.807352         0.725861   
3           3.0   50.0           10.0        0.805050         0.723273   
4           4.0   50.0           20.0        0.799307         0.721802   

   Valid Recall  
0      0.694055  
1      0.681833  
2      0.663302  
3      0.657231  
4      0.631762  

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}133}]:} \PY{c+c1}{\PYZsh{}keeping the best RF model}
          \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}
\end{Verbatim}


    We can also look at the performance of the random forest on a precision
recall curve below when the probability cutoff for positive
classification is continually adjusted. Generally there is a tradeoff
such that increasing precision leads to decreasing recall. Our goal
therefore is to minimize this difference and ensuring that accuracy is
also improved in the process

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}131}]:} \PY{n}{precision}\PY{p}{,} \PY{n}{recall}\PY{p}{,} \PY{n}{thresholds} \PY{o}{=} \PY{n}{metrics}\PY{o}{.}\PY{n}{precision\PYZus{}recall\PYZus{}curve}\PY{p}{(}\PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{rf\PYZus{}preds}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{step}\PY{p}{(}\PY{n}{recall}\PY{p}{,} \PY{n}{precision}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
                   \PY{n}{where}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{recall}\PY{p}{,} \PY{n}{precision}\PY{p}{,} \PY{n}{step}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{post}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.1}\PY{p}{,}
                           \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Recall}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.05}\PY{p}{]}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}131}]:} (0.0, 1.0)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_41_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \section{PART E - FEATURE
ENGINEERING}\label{part-e---feature-engineering}

\subsection{Feature Importance}\label{feature-importance}

The models we have so far do average in terms of performance. They
either perform as well as the baseline or worse. That is not helpeful as
we want to use ML to make better predictions than naive approaches. For
this reason we have to derive new features that can better identify key
trends and information for the model to learn from. But how do we go
about deciding what to derive and how?

One (simple) way to approach this is to see the feature importance of a
random forest which can tell us which features contribute the most in
information gain to a random forest. From the top features we can deduce
hypotheses that can be used to further develop new features.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}134}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}random\PYZus{}forest\PYZus{}importance}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{,} \PY{n}{rf\PYZus{}model}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{}features = iris[\PYZsq{}feature\PYZus{}names\PYZsq{}]}
              \PY{n}{feature\PYZus{}names} \PY{o}{=} \PY{n}{airbnb\PYZus{}data}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{columns}
              \PY{n}{importances} \PY{o}{=} \PY{n}{rf\PYZus{}model}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}}
              \PY{n}{indices} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{n}{importances}\PY{p}{)}
          
              \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Random Forest Feature Importances}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{barh}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{indices}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{importances}\PY{p}{[}\PY{n}{indices}\PY{p}{]}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{b}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{align}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{indices}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{p}{[}\PY{n}{feature\PYZus{}names}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n}{indices}\PY{p}{]}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Relative Importance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
          
          \PY{n}{plot\PYZus{}random\PYZus{}forest\PYZus{}importance}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{,} \PY{n}{rf\PYZus{}model}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_43_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \section{Hypotheses for Feature
Engineering}\label{hypotheses-for-feature-engineering}

Looking at the feature importance rank a few things stand out:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  that historical time based features that give a historical status of
  booking rates (occ\_occupancy\_trailing\_90\_ds for example) are
  highly predictive. Essentially, what happened in the past is highly
  predictive of what will happen in the future. If we build new features
  then we want to capture the historical time based availability for a
  listing in the recent past.
\item
  The price of the listing is extremely predictive. this makes sense as
  the lower the price the less a customer has to spend. We should derive
  sharper measures of price relative to other listings
\item
  Features that measure demand implicitly like views and clicks can be
  very predictive as well. We should define better measures of listing
  and market demand
\end{enumerate}

    \section{Feature Engineering V1}\label{feature-engineering-v1}

Based on the above findings and hypotheses I create more features by
either deriving historical averages or by transforming existing features
into more useful measure distriubutions. These features are of the
following types:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  For each listing I go back a few periods for which we have data
  (between 1 and 8 prior periods) and get the historical booking status
  of the listing in that period. I use this historical availability to
  build new features based on whether a listing was available or not N
  periods in the past. I also look at the \% change in booking averages
  etc;
\item
  I look at the price changes in the last few periods. These can be
  indicative of whether the price increased or decreased recently
  relative to the last period or last week etc
\item
  Similarly, I look at historically what was the volume of views that
  listing got in the recent past and not just today
\item
  Finally I do a few feature transformations on market and KDT features
  to ensure that we have KPIS for the market or KDT that make more sense
  vs just absolute numbers. For example:
  general\_market\_search\_to\_contact\_rate = searches/contacts. By
  transforming two given features into a KPI \% we can better articulate
  the key trend a model should be looking at when measuring demand. That
  is a higher search to contact rate is indicative of greater demand.
  Similarly, by deriving KDT availability \% and also price relative to
  KDT average we can create features that might help improve performance
  as they are transformed into more explicit relationships.
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}152}]:} \PY{c+c1}{\PYZsh{}simple moving average helper function to get historical averages for some features}
          \PY{k}{def} \PY{n+nf}{sma}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{n}\PY{p}{)}\PY{p}{:}
              \PY{k}{return} \PY{n}{data}\PY{o}{.}\PY{n}{rolling}\PY{p}{(}\PY{n}{window}\PY{o}{=}\PY{n}{n}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
          
          \PY{k}{def} \PY{n+nf}{create\PYZus{}new\PYZus{}features\PYZus{}listing}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
              
              \PY{c+c1}{\PYZsh{}\PYZsh{}for each listing we go back in time and look if they were booked or not}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}3\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}7\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}3\PYZus{}booked\PYZus{}perc\PYZus{}gain}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}3\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}7\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
              \PY{c+c1}{\PYZsh{}historical price averages and time change indicators}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}avail\PYZus{}period\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}    
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}week\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}avail\PYZus{}period\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}    
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}change\PYZus{}since\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}avail\PYZus{}period\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}change\PYZus{}since\PYZus{}last\PYZus{}week\PYZus{}avg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}week\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
           
              \PY{c+c1}{\PYZsh{}historical listing views and listing rates of change}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}    
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}  
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}views\PYZus{}day\PYZus{}change}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}views\PYZus{}week\PYZus{}avg\PYZus{}change}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}occupancy transformed to relative occupanices based on historical rates}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occupancy\PYZus{}7\PYZus{}days\PYZus{}change\PYZus{}relative\PYZus{}90\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}7\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}14\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occupancy\PYZus{}7\PYZus{}days\PYZus{}change\PYZus{}relative\PYZus{}14\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}7\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}trailing\PYZus{}90\PYZus{}ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}listing click to inquiry score transformed to a KPI ratio}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{click\PYZus{}to\PYZus{}inquiry\PYZus{}score\PYZus{}ratio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p3\PYZus{}inquiry\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p2\PYZus{}p3\PYZus{}click\PYZus{}through\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}market KPI metrics to track the health and demand of the market itself}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}search\PYZus{}to\PYZus{}contact\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}contacts\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}unique\PYZus{}searchers\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}contact\PYZus{}to\PYZus{}reservation\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}reservation\PYZus{}requests\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}contacts\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}reservation\PYZus{}to\PYZus{}booked\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}is\PYZus{}booked\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}reservation\PYZus{}requests\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}availability\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}is\PYZus{}booked\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{p}{(}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}is\PYZus{}booked\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{+} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}available\PYZus{}listings\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{}kdt metrics to understand demand and available for that kdt}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kdt\PYZus{}availability\PYZus{}percentage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}n\PYZus{}available\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}n\PYZus{}active\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kdt\PYZus{}views\PYZus{}per\PYZus{}available\PYZus{}listing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}listing\PYZus{}views\PYZus{}0\PYZus{}6\PYZus{}avg\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}n\PYZus{}active\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}\PYZsh{}the price of the listing relative to other kdt listings}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}relative\PYZus{}kdt\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}m\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZus{}n100\PYZus{}p50}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}relative\PYZus{}kdt\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZus{}avail}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}m\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZus{}available\PYZus{}n100\PYZus{}p50}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}\PYZsh{} fill missing values with \PYZhy{}1 and replace infinity with 0}
              \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{mode}\PY{o}{.}\PY{n}{use\PYZus{}inf\PYZus{}as\PYZus{}na} \PY{o}{=} \PY{k+kc}{True}
              \PY{n}{data} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}data = data.replace(\PYZsq{}\PYZhy{}inf\PYZsq{},0)}
              \PY{c+c1}{\PYZsh{}data[np.isneginf(data)] = 0}
          
              \PY{k}{return} \PY{n}{data}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}136}]:} \PY{n}{airbnb\PYZus{}derived\PYZus{}featrures\PYZus{}data} \PY{o}{=} \PY{n}{create\PYZus{}new\PYZus{}features\PYZus{}listing}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}derived\PYZus{}featrures\PYZus{}data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}136}]:}         dim\_is\_requested    ds\_night          ds  \textbackslash{}
          92617                  0  2015-01-03  2014-12-04   
          45319                  0  2015-01-04  2014-12-05   
          4394                   0  2015-01-07  2014-12-08   
          177135                 0  2015-01-13  2014-12-14   
          43123                  0  2015-01-14  2014-12-15   
          
                                       id\_listing\_anon  \textbackslash{}
          92617   00004783-f5e1-47cf-90bf-3daad76d1a09   
          45319   00004783-f5e1-47cf-90bf-3daad76d1a09   
          4394    00004783-f5e1-47cf-90bf-3daad76d1a09   
          177135  00004783-f5e1-47cf-90bf-3daad76d1a09   
          43123   00004783-f5e1-47cf-90bf-3daad76d1a09   
          
                                          id\_user\_anon  m\_effective\_daily\_price  \textbackslash{}
          92617   251917ad-d2e8-467d-ace3-7e5699e16b89               308.737257   
          45319   251917ad-d2e8-467d-ace3-7e5699e16b89               308.386883   
          4394    251917ad-d2e8-467d-ace3-7e5699e16b89               307.170580   
          177135  251917ad-d2e8-467d-ace3-7e5699e16b89               311.518725   
          43123   251917ad-d2e8-467d-ace3-7e5699e16b89               311.522589   
          
                  m\_pricing\_cleaning\_fee   dim\_lat   dim\_lng  dim\_person\_capacity  \textbackslash{}
          92617                85.950775  48.87363  2.312445                    3   
          45319                85.809113  48.87363  2.312445                    3   
          4394                 85.542191  48.87363  2.312445                    3   
          177135               85.266556  48.87363  2.312445                    3   
          43123                85.177414  48.87363  2.312445                    3   
          
                  dim\_is\_instant\_bookable  m\_checkouts  m\_reviews  \textbackslash{}
          92617                         0          0.0        0.0   
          45319                         0          0.0        0.0   
          4394                          0          0.0        0.0   
          177135                        0          0.0        0.0   
          43123                         0          0.0        0.0   
          
                  days\_since\_last\_booking  cancel\_policy  image\_quality\_score  \textbackslash{}
          92617                      -1.0              3             0.095232   
          45319                      -1.0              3             0.095232   
          4394                       -1.0              3             0.095232   
          177135                     -1.0              3             0.095232   
          43123                      -1.0              3             0.095232   
          
                  m\_total\_overall\_rating  m\_professional\_pictures  \textbackslash{}
          92617                      0.0                      0.0   
          45319                      0.0                      0.0   
          4394                       0.0                      0.0   
          177135                     0.0                      0.0   
          43123                      0.0                      0.0   
          
                  dim\_has\_wireless\_internet  ds\_night\_day\_of\_week  ds\_night\_day\_of\_year  \textbackslash{}
          92617                           1                     6                     3   
          45319                           1                     0                     4   
          4394                            1                     3                     7   
          177135                          1                     2                    13   
          43123                           1                     3                    14   
          
                  ds\_checkin\_gap  ds\_checkout\_gap  occ\_occupancy\_plus\_minus\_7\_ds\_night  \textbackslash{}
          92617              7.0              7.0                                 -1.0   
          45319              7.0              7.0                                 -1.0   
          4394               7.0              7.0                                 -1.0   
          177135             7.0              7.0                                 -1.0   
          43123              7.0              7.0                                 -1.0   
          
                  occ\_occupancy\_plus\_minus\_14\_ds\_night  occ\_occupancy\_trailing\_90\_ds  \textbackslash{}
          92617                                   -1.0                           0.0   
          45319                                   -1.0                           0.0   
          4394                                    -1.0                           0.0   
          177135                                  -1.0                           0.0   
          43123                                   -1.0                           0.0   
          
                  m\_minimum\_nights  m\_maximum\_nights  price\_booked\_most\_recent  \textbackslash{}
          92617                1.0            1125.0                      -1.0   
          45319                1.0            1125.0                      -1.0   
          4394                 1.0            1125.0                      -1.0   
          177135               1.0            1125.0                      -1.0   
          43123                1.0            1125.0                      -1.0   
          
                  p2\_p3\_click\_through\_score  p3\_inquiry\_score  \textbackslash{}
          92617                        -1.0              -1.0   
          45319                        -1.0              -1.0   
          4394                         -1.0              -1.0   
          177135                       -1.0              -1.0   
          43123                        -1.0              -1.0   
          
                  listing\_m\_listing\_views\_2\_6\_ds\_night\_decay  \textbackslash{}
          92617                                     0.000000   
          45319                                     0.000000   
          4394                                      0.733333   
          177135                                    0.000000   
          43123                                     0.000000   
          
                  general\_market\_m\_unique\_searchers\_0\_6\_ds\_night  \textbackslash{}
          92617                                      1673.857143   
          45319                                      1288.428571   
          4394                                       1162.428571   
          177135                                     1104.714286   
          43123                                      1118.285714   
          
                  general\_market\_m\_contacts\_0\_6\_ds\_night  \textbackslash{}
          92617                               782.571429   
          45319                               563.000000   
          4394                                440.285714   
          177135                              418.142857   
          43123                               419.285714   
          
                  general\_market\_m\_reservation\_requests\_0\_6\_ds\_night  \textbackslash{}
          92617                                          144.142857    
          45319                                          102.714286    
          4394                                            76.428571    
          177135                                          62.571429    
          43123                                           62.000000    
          
                  general\_market\_m\_is\_booked\_0\_6\_ds\_night  \textbackslash{}
          92617                                       1.0   
          45319                                       1.0   
          4394                                        1.0   
          177135                                      1.0   
          43123                                       1.0   
          
                  m\_available\_listings\_ds\_night  kdt\_score  \textbackslash{}
          92617                           19373   0.863636   
          45319                           19654   0.727273   
          4394                            20774   0.863636   
          177135                          21457   0.454545   
          43123                           21513   0.727273   
          
                  r\_kdt\_listing\_views\_0\_6\_avg\_n100  r\_kdt\_n\_active\_n100  \textbackslash{}
          92617                           3.532653                124.0   
          45319                           2.262585                123.0   
          4394                            1.938776                122.0   
          177135                          2.367347                122.0   
          43123                           2.151020                123.0   
          
                  r\_kdt\_n\_available\_n100  r\_kdt\_m\_effective\_daily\_price\_n100\_p50  \textbackslash{}
          92617                     61.0                              166.718119   
          45319                     61.0                              160.361179   
          4394                      66.0                              159.728702   
          177135                    72.0                              160.743662   
          43123                     73.0                              158.253475   
          
                  r\_kdt\_m\_effective\_daily\_price\_available\_n100\_p50  \textbackslash{}
          92617                                         194.504472   
          45319                                         185.032130   
          4394                                          165.872113   
          177135                                        186.911235   
          43123                                         171.337424   
          
                  r\_kdt\_m\_effective\_daily\_price\_booked\_n100\_p50  dim\_market\_Paris  \textbackslash{}
          92617                                            -1.0                 1   
          45319                                            -1.0                 1   
          4394                                             -1.0                 1   
          177135                                           -1.0                 1   
          43123                                            -1.0                 1   
          
                  dim\_market\_San Francisco  dim\_room\_type\_Private room  \textbackslash{}
          92617                          0                           0   
          45319                          0                           0   
          4394                           0                           0   
          177135                         0                           0   
          43123                          0                           0   
          
                  dim\_room\_type\_Shared room  last\_available\_period\_booking  \textbackslash{}
          92617                           0                           -1.0   
          45319                           0                            0.0   
          4394                            0                            0.0   
          177135                          0                            0.0   
          43123                           0                            0.0   
          
                  last\_3\_period\_available\_period\_booking  \textbackslash{}
          92617                                     -1.0   
          45319                                     -1.0   
          4394                                      -1.0   
          177135                                     0.0   
          43123                                      0.0   
          
                  last\_7\_period\_available\_period\_booking  last\_3\_booked\_perc\_gain  \textbackslash{}
          92617                                     -1.0                     -1.0   
          45319                                     -1.0                     -1.0   
          4394                                      -1.0                     -1.0   
          177135                                    -1.0                     -1.0   
          43123                                     -1.0                     -1.0   
          
                  last\_avail\_period\_effective\_daily\_price  \textbackslash{}
          92617                                308.737257   
          45319                                308.386883   
          4394                                 307.170580   
          177135                               311.518725   
          43123                                311.522589   
          
                  last\_week\_effective\_daily\_price  price\_change\_since\_last\_day  \textbackslash{}
          92617                              -1.0                          1.0   
          45319                              -1.0                          1.0   
          4394                               -1.0                          1.0   
          177135                             -1.0                          1.0   
          43123                              -1.0                          1.0   
          
                  price\_change\_since\_last\_week\_avg  \textbackslash{}
          92617                               -1.0   
          45319                               -1.0   
          4394                                -1.0   
          177135                              -1.0   
          43123                               -1.0   
          
                  listing\_m\_listing\_views\_2\_6\_ds\_night\_last\_day  \textbackslash{}
          92617                                        0.000000   
          45319                                        0.000000   
          4394                                         0.733333   
          177135                                       0.000000   
          43123                                        0.000000   
          
                  listing\_m\_listing\_views\_2\_6\_ds\_night\_last\_week  \textbackslash{}
          92617                                             -1.0   
          45319                                             -1.0   
          4394                                              -1.0   
          177135                                            -1.0   
          43123                                             -1.0   
          
                  listing\_views\_day\_change  listing\_views\_week\_avg\_change  \textbackslash{}
          92617                       -1.0                           -1.0   
          45319                       -1.0                           -1.0   
          4394                         1.0                           -1.0   
          177135                      -1.0                           -1.0   
          43123                       -1.0                           -1.0   
          
                  occupancy\_7\_days\_change\_relative\_90\_days  \textbackslash{}
          92617                                        1.0   
          45319                                        1.0   
          4394                                         1.0   
          177135                                       1.0   
          43123                                        1.0   
          
                  occupancy\_7\_days\_change\_relative\_14\_days  \textbackslash{}
          92617                                       -1.0   
          45319                                       -1.0   
          4394                                        -1.0   
          177135                                      -1.0   
          43123                                       -1.0   
          
                  click\_to\_inquiry\_score\_ratio  general\_market\_search\_to\_contact\_rate  \textbackslash{}
          92617                            1.0                               0.467526   
          45319                            1.0                               0.436966   
          4394                             1.0                               0.378764   
          177135                           1.0                               0.378508   
          43123                            1.0                               0.374936   
          
                  general\_market\_contact\_to\_reservation\_rate  \textbackslash{}
          92617                                     0.184191   
          45319                                     0.182441   
          4394                                      0.173589   
          177135                                    0.149641   
          43123                                     0.147871   
          
                  general\_market\_reservation\_to\_booked\_rate  \textbackslash{}
          92617                                    0.006938   
          45319                                    0.009736   
          4394                                     0.013084   
          177135                                   0.015982   
          43123                                    0.016129   
          
                  general\_market\_availability\_rate  kdt\_availability\_percentage  \textbackslash{}
          92617                           0.999948                     0.491935   
          45319                           0.999949                     0.495935   
          4394                            0.999952                     0.540984   
          177135                          0.999953                     0.590164   
          43123                           0.999954                     0.593496   
          
                  kdt\_views\_per\_available\_listing  \textbackslash{}
          92617                          0.028489   
          45319                          0.018395   
          4394                           0.015892   
          177135                         0.019404   
          43123                          0.017488   
          
                  price\_relative\_kdt\_effective\_daily\_price  \textbackslash{}
          92617                                   1.851852   
          45319                                   1.923077   
          4394                                    1.923077   
          177135                                  1.937984   
          43123                                   1.968504   
          
                  price\_relative\_kdt\_effective\_daily\_price\_avail  
          92617                                         1.587302  
          45319                                         1.666667  
          4394                                          1.851852  
          177135                                        1.666667  
          43123                                         1.818182  
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}137}]:} \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}featrures\PYZus{}data}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
\end{Verbatim}


    \subsection{Model Performance V2 - With Feature Engineering
Features}\label{model-performance-v2---with-feature-engineering-features}

After feature engineering we can see that both the logistic and random
forest models greatly improve in performance across accuracy, precision
and recall. In fact the random forest now beats the baseline by around
at least 4-15\% across all metrics accuracy, precision, and recall.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}141}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Logistic Regression with derived features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{a}\PY{p}{,} \PY{n}{p}\PY{p}{,} \PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Logistic Regression with derived features
The out of sample performance on validation data is:
The accuracy is 0.820
The precision is 0.750
The recall is 0.678

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}145}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Random Forest with derived features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Random Forest with derived features
The out of sample performance on validation data is:
The accuracy is 0.854
The precision is 0.779
The recall is 0.773

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}400}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{For Comparison here is the baseline performance again}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Baseline Accuracy is: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{baseline\PYZus{}accuracy}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Baseline Precision is: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{baseline\PYZus{}precision}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Baseline Recall is: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+si}{\PYZpc{}.3f}\PY{l+s+s2}{\PYZdq{}} \PY{o}{\PYZpc{}} \PY{n}{baseline\PYZus{}recall}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
For Comparison here is the baseline performance again
The Baseline Accuracy is: 0.818
The Baseline Precision is: 0.742
The Baseline Recall is: 0.684

    \end{Verbatim}

    Looking at the feature importance we can see that the feature
engineering definitely helped as the most dominant features now are all
the historical and price based features we built based on the
hypotheses.

The most important feature now is if a listing was booked in the last
avaialable period. Therefore, if a listing was booked in the past is
most predictive if a listing will be booked again. Similarly, a recent
price change can really affect a booking. Price increases can lead to
impulse bookings. And Price decreases might convince users on the fence
etc; These validates our hypotheses.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}147}]:} \PY{n}{plot\PYZus{}random\PYZus{}forest\PYZus{}importance}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}featrures\PYZus{}data}\PY{p}{,} \PY{n}{rf\PYZus{}model}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_54_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \section{Feature Engineering V2}\label{feature-engineering-v2}

With that in mind lets revisit the features and create even more time
based features to see if we can extract more performance from these same
set of ideas.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}148}]:} \PY{k}{def} \PY{n+nf}{create\PYZus{}new\PYZus{}features\PYZus{}listing}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{drop\PYZus{}missing}\PY{p}{)}\PY{p}{:}
              
              \PY{c+c1}{\PYZsh{}\PYZsh{}for each listing we go back in time}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lag\PYZus{}2\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lag\PYZus{}3\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lag\PYZus{}4\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lag\PYZus{}5\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lag\PYZus{}6\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lag\PYZus{}7\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{7}\PY{p}{)}\PY{p}{)}
          
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}3\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}7\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{}historical listing views and listing time change indicators}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}    
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}  
              
              \PY{c+c1}{\PYZsh{}historical price averages and time change indicators}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}avail\PYZus{}period\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}    
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}week\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}avail\PYZus{}period\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}    
              
              \PY{k}{if} \PY{n}{drop\PYZus{}missing} \PY{o}{==} \PY{k+kc}{True}\PY{p}{:}
                  \PY{n}{data} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{inplace} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{}\PYZsh{}percentage changes for the above}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}views\PYZus{}day\PYZus{}change}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}views\PYZus{}week\PYZus{}avg\PYZus{}change}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}decay}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{listing\PYZus{}m\PYZus{}listing\PYZus{}views\PYZus{}2\PYZus{}6\PYZus{}ds\PYZus{}night\PYZus{}last\PYZus{}week}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
            
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}change\PYZus{}since\PYZus{}last\PYZus{}day}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}avail\PYZus{}period\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}change\PYZus{}since\PYZus{}last\PYZus{}week\PYZus{}avg}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}week\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
           
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}day\PYZus{}booked\PYZus{}perc\PYZus{}gain\PYZus{}7\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}7\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}day\PYZus{}booked\PYZus{}perc\PYZus{}gain\PYZus{}7\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}3\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}3\PYZus{}days\PYZus{}booked\PYZus{}perc\PYZus{}gain\PYZus{}7\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}3\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{last\PYZus{}7\PYZus{}period\PYZus{}available\PYZus{}period\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
              \PY{c+c1}{\PYZsh{}occupancy transformed to relative occupanices based on historical rates}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occupancy\PYZus{}7\PYZus{}days\PYZus{}change\PYZus{}relative\PYZus{}90\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}7\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}14\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occupancy\PYZus{}7\PYZus{}days\PYZus{}change\PYZus{}relative\PYZus{}14\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}plus\PYZus{}minus\PYZus{}7\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{occ\PYZus{}occupancy\PYZus{}trailing\PYZus{}90\PYZus{}ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}listing click to inquiry score transformed to a KPI ratio}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{click\PYZus{}to\PYZus{}inquiry\PYZus{}score\PYZus{}ratio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p3\PYZus{}inquiry\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p2\PYZus{}p3\PYZus{}click\PYZus{}through\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}market KPI metrics to track the health and demand of the market itself}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}search\PYZus{}to\PYZus{}contact\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}contacts\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}unique\PYZus{}searchers\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}contact\PYZus{}to\PYZus{}reservation\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}reservation\PYZus{}requests\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}contacts\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}reservation\PYZus{}to\PYZus{}booked\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}is\PYZus{}booked\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}reservation\PYZus{}requests\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}availability\PYZus{}rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}is\PYZus{}booked\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{p}{(}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{general\PYZus{}market\PYZus{}m\PYZus{}is\PYZus{}booked\PYZus{}0\PYZus{}6\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{+} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}available\PYZus{}listings\PYZus{}ds\PYZus{}night}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{}kdt metrics to understand demand and available for that kdt}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kdt\PYZus{}availability\PYZus{}percentage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}n\PYZus{}available\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}n\PYZus{}active\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kdt\PYZus{}views\PYZus{}per\PYZus{}available\PYZus{}listing}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}listing\PYZus{}views\PYZus{}0\PYZus{}6\PYZus{}avg\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}n\PYZus{}active\PYZus{}n100}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{c+c1}{\PYZsh{}\PYZsh{}the price of the listing relative to other kdt listings}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}relative\PYZus{}kdt\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}m\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZus{}n100\PYZus{}p50}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{price\PYZus{}relative\PYZus{}kdt\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZus{}avail}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r\PYZus{}kdt\PYZus{}m\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZus{}available\PYZus{}n100\PYZus{}p50}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              
              \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{mode}\PY{o}{.}\PY{n}{use\PYZus{}inf\PYZus{}as\PYZus{}na} \PY{o}{=} \PY{k+kc}{True}
              \PY{n}{data} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{n}{data} \PY{o}{=} \PY{n}{data}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}data = data.replace(\PYZsq{}\PYZhy{}inf\PYZsq{},0)}
              \PY{c+c1}{\PYZsh{}data[np.isneginf(data)] = 0}
          
              \PY{k}{return} \PY{n}{data}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}149}]:} \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v2} \PY{o}{=} \PY{n}{create\PYZus{}new\PYZus{}features\PYZus{}listing}\PY{p}{(}\PY{n}{airbnb\PYZus{}data}\PY{p}{,} \PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}150}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Logistic Regression with derived features V2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v2}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
          \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Logistic Regression with derived features V2
The out of sample performance on validation data is:
The accuracy is 0.824
The precision is 0.752
The recall is 0.691

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}151}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Random Forest with derived features V2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Random Forest with derived features V2
The out of sample performance on validation data is:
The accuracy is 0.852
The precision is 0.774
The recall is 0.773

    \end{Verbatim}

    \subsection{Feature Engineering V2
Evaluation}\label{feature-engineering-v2-evaluation}

After creating more features based on time we see that the random forest
doesn't improve much in performance although the log regression does see
a slight improvement in recall (69.1\% vs 67.8\%). It seems like we have
extracted a lot of information from historical availability and trying
to transform and derive more will lead to marginal if any improvements.
It's time to focus on other ideas.

\section{Feature Engineering V3}\label{feature-engineering-v3}

\subsection{Creating User Based
Features}\label{creating-user-based-features}

One of the ways to improve feature engineering would be to aggregate at
the user level instead of the listing. Users can have multiple listings.
The hypothesis here is that good users will have high in demand listings
everywhere. So maybe if we aggregatate at the user level we can get
better measures of listing demand and likelihood to book based on who
the user is. It is not feasible to use the user id as a feature as there
are 7K+users and many will have sparse data points which can lead to
overfitting but we can average out booking trends for a user instead

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}153}]:} \PY{k}{def} \PY{n+nf}{create\PYZus{}host\PYZus{}features}\PY{p}{(}\PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{}this function groups by user instead of listing}
              \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}user\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sum}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}listings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}user\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}airbnb\PYZus{}data\PYZus{}2[\PYZsq{}user\PYZus{}average\PYZus{}rating\PYZsq{}] = airbnb\PYZus{}data\PYZus{}2.groupby([\PYZsq{}id\PYZus{}user\PYZus{}anon\PYZsq{},\PYZsq{}ds\PYZsq{}])[\PYZsq{}m\PYZus{}total\PYZus{}overall\PYZus{}rating\PYZsq{}].transform(\PYZsq{}mean\PYZsq{})}
              \PY{c+c1}{\PYZsh{}airbnb\PYZus{}data\PYZus{}2[\PYZsq{}user\PYZus{}average\PYZus{}price\PYZsq{}] = airbnb\PYZus{}data\PYZus{}2.groupby([\PYZsq{}id\PYZus{}user\PYZus{}anon\PYZsq{},\PYZsq{}ds\PYZsq{}])[\PYZsq{}m\PYZus{}effective\PYZus{}daily\PYZus{}price\PYZsq{}].transform(\PYZsq{}mean\PYZsq{})}
              \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked\PYZus{}percentage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}listings}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
              \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked\PYZus{}percentage\PYZus{}previous\PYZus{}period}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}user\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked\PYZus{}percentage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
              \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked\PYZus{}percentage\PYZus{}previous\PYZus{}period\PYZus{}7\PYZus{}days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked\PYZus{}percentage\PYZus{}previous\PYZus{}period}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}
              \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{user\PYZus{}booked\PYZus{}percentage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
              
              \PY{n}{airbnb\PYZus{}data\PYZus{}2} \PY{o}{=} \PY{n}{airbnb\PYZus{}data\PYZus{}2}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
              
              \PY{k}{return} \PY{n}{airbnb\PYZus{}data\PYZus{}2}
          
          \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v3} \PY{o}{=} \PY{n}{create\PYZus{}host\PYZus{}features}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v2}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}155}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Logistic Regression with derived features V3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v3}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
          \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Logistic Regression with derived features V3
The out of sample performance on validation data is:
The accuracy is 0.826
The precision is 0.754
The recall is 0.695

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}156}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Random Forest with derived features V3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Random Forest with derived features V3
The out of sample performance on validation data is:
The accuracy is 0.851
The precision is 0.775
The recall is 0.771

    \end{Verbatim}

    But from the above we can see that building user based features didn't
add any improvement to model performance. Accuracy remains similar for
both models.

\section{Feature Engineering V4 (Final Feature
Version)}\label{feature-engineering-v4-final-feature-version}

There is one problem with our historical features we created earlier.
Time Gaps in the data. As noted earlier, days for which a listing was
not already available were removed from the dataset when given.

But these days could have been days that were already booked. As such
these days could have been very predictive as they indicate a listing
has been booked and therefore migth be booked again in the future. If we
remove these days we lose that information. I circumvented this problem
by inferring the days that were booked.

I first created a base table that was the cross product of each day and
listing id. Then I merged that with our data and if a match was not
found for a listing and a date combination in our data, I flagged that
listing and date combination as 1 implying that it was already booked.
Then I created the same historical flags like before. (Dates after ds
were discarded as they were meaningless).

Now we have a true time series, where we can say for every day whether
the last N days were booked (or unavialble) or not.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}157}]:} \PY{k+kn}{import} \PY{n+nn}{itertools}
          \PY{k}{def} \PY{n+nf}{create\PYZus{}listing\PYZus{}date\PYZus{}base}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
              \PY{n}{unique\PYZus{}dates} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}
              \PY{n}{unique\PYZus{}listings} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}
          
              \PY{n}{base\PYZus{}table} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{itertools}\PY{o}{.}\PY{n}{product}\PY{p}{(}\PY{n}{unique\PYZus{}listings}\PY{p}{,}\PY{n}{unique\PYZus{}dates}\PY{p}{)}\PY{p}{)}\PY{p}{)}
              \PY{n}{base\PYZus{}table} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{base\PYZus{}table}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{base\PYZus{}table} \PY{o}{=} \PY{n}{base\PYZus{}table}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{base\PYZus{}table} \PY{o}{=} \PY{n}{base\PYZus{}table}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{data}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
                                            \PY{p}{,} \PY{n}{on} \PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{how}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              
              \PY{c+c1}{\PYZsh{}I assume that if a record is missing for a day then that listing is either unavailable or booked}
              \PY{c+c1}{\PYZsh{}Hence it is flagged as 1.}
              \PY{n}{base\PYZus{}table} \PY{o}{=} \PY{n}{base\PYZus{}table}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
              \PY{k}{return} \PY{n}{base\PYZus{}table}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}158}]:} \PY{n}{base\PYZus{}listing\PYZus{}date} \PY{o}{=} \PY{n}{create\PYZus{}listing\PYZus{}date\PYZus{}base}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v3}\PY{p}{)}
          \PY{n}{base\PYZus{}listing\PYZus{}date}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{previous\PYZus{}day\PYZus{}unavailablity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{base\PYZus{}listing\PYZus{}date}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n}{x}\PY{o}{.}\PY{n}{shift}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
          \PY{n}{base\PYZus{}listing\PYZus{}date}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{previous\PYZus{}3\PYZus{}day\PYZus{}avg\PYZus{}unavailability}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{base\PYZus{}listing\PYZus{}date}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{previous\PYZus{}day\PYZus{}unavailablity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}   
          \PY{n}{base\PYZus{}listing\PYZus{}date}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{previous\PYZus{}7\PYZus{}day\PYZus{}avg\PYZus{}unavailability}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{base\PYZus{}listing\PYZus{}date}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{previous\PYZus{}day\PYZus{}unavailablity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{sma}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4} \PY{o}{=} \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v3}\PY{o}{.}\PY{n}{merge}\PY{p}{(}\PY{n}{base\PYZus{}listing\PYZus{}date}\PY{p}{,} \PY{n}{on} \PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{id\PYZus{}listing\PYZus{}anon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ds}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{how}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4} \PY{o}{=} \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested\PYZus{}y}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
          \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4} \PY{o}{=} \PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4}\PY{o}{.}\PY{n}{rename}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested\PYZus{}x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}181}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Logistic Regression with derived features V4}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
          \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Logistic Regression with derived features V4
The out of sample performance on validation data is:
The accuracy is 0.833
The precision is 0.760
The recall is 0.721

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}182}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of Random Forest with derived features V4}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of Random Forest with derived features V4
The out of sample performance on validation data is:
The accuracy is 0.852
The precision is 0.771
The recall is 0.783

    \end{Verbatim}

    \subsection{Final Feature Evaluation}\label{final-feature-evaluation}

From the above it can be seen that fixing the time gap issue and
creating true last N day availability metrics helped improve the
performance of the Logistic Regression Model significantly. Accuracy
jumped from 0.826 to 0.833 and Recall especially saw a big increase from
0.695 to 0.721. The random forest however performed as well as before
without a major improvement. Therefore these features helped the Log
regression model but didn't help the Random Forest so much. Irrespective
we will use this as the final feature data set for our model evalution.

\subsubsection{An Important Note on Feature Selection from an
Engineering
Standpoint}\label{an-important-note-on-feature-selection-from-an-engineering-standpoint}

The final set of features include lots of useless highly correlated
features that are essentially measuring the same thing. Due to time
constraints, I am unable to do feature selection here but if time
permitted I would have removed highly correlated and unimportant
features from the dataset. For log regression, this can lead to
improvements in performance although for Random Forests it tends to
matter less.

Irrespective of performance gain, it is generally better to have a
simple model (if performance is not compromised) because when models go
into production and have to be refreshed daily, having tons of features
that add nothing to the model can make it difficult to maintain data
pipelines and ensure data integrity. Assuming two models with similar
accuracy but one with less feature complexity and space, the more simple
model should be productionized.

    \section{PART F - ADVANCED ALGORITHMIC
IMPROVEMENTS}\label{part-f---advanced-algorithmic-improvements}

Witrh feature engineering finalized it is now time to turn attention
again to the algorithm. So far we have been looking at only log
regression and random forersts. But more powerful methods like:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Neural Networks
\item
  Ensembling Techniques (Stacking or Blending)
\end{enumerate}

can also be utilized to help improve model performance from an
algorithmic standpoint. In the following section I will now try to see
if model accuracy (and precision and recall) can be improved by using
even more advanced techniques

\subsection{a) Neural Networks}\label{a-neural-networks}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}186}]:} \PY{k}{def} \PY{n+nf}{train\PYZus{}neural\PYZus{}network}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{input\PYZus{}len}\PY{p}{,} \PY{n}{e}\PY{p}{,} \PY{n}{batch}\PY{p}{,} \PY{n}{valid\PYZus{}split}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} define the architecture for the simple feed forward network}
              \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{o}{=}\PY{n}{input\PYZus{}len}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.25}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{25}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sigmoid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.25}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sigmoid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{binary\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{n}{e}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{validation\PYZus{}split}\PY{o}{=}\PY{n}{valid\PYZus{}split}\PY{p}{)}
              \PY{k}{return} \PY{n}{model}
\end{Verbatim}


    Lets first start off with a simple neural network with random
parameters. This neural network has 3 hidden layers with different
neurons. It also uses neuron dropout to help achieve better
generalization. The Relu and Sigmoid activation functions are used as
they are especially good for classification problems.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}187}]:} \PY{n}{nn\PYZus{}model} \PY{o}{=} \PY{n}{train\PYZus{}neural\PYZus{}network}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{25}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}189}]:} \PY{n}{nn\PYZus{}pred} \PY{o}{=} \PY{n}{nn\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Performance of the Neural Network using the Final Set of Features:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{nn\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The Performance of the Neural Network using the Final Set of Features:
The out of sample performance on validation data is:
The accuracy is 0.852
The precision is 0.762
The recall is 0.799

    \end{Verbatim}

    Looking above, just with random hyperparameters we already have a neural
network that does as well as the random forest in accuracy and actually
beats all models in Recall showing a big jump up to almost 80\%! Let's
see if we can do better with another set of parameters.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}194}]:} \PY{c+c1}{\PYZsh{}tuning the neural net}
          \PY{k}{def} \PY{n+nf}{train\PYZus{}neural\PYZus{}network}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{input\PYZus{}len}\PY{p}{,} \PY{n}{e}\PY{p}{,} \PY{n}{batch}\PY{p}{,} \PY{n}{lr}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} define the architecture for the simple feed forward network}
              \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{128}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{o}{=}\PY{n}{input\PYZus{}len}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.25}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.25}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{32}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sigmoid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sigmoid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
              \PY{n}{optimizer} \PY{o}{=} \PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{n}{lr}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{binary\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{n}{optimizer}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
              \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{n}{e}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{validation\PYZus{}data} \PY{o}{=} \PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{)}\PY{p}{)}
              \PY{k}{return} \PY{n}{model}
          
          \PY{n}{nn\PYZus{}model} \PY{o}{=} \PY{n}{train\PYZus{}neural\PYZus{}network}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{25}\PY{p}{,} \PY{l+m+mi}{128}\PY{p}{,} \PY{l+m+mf}{0.001}\PY{p}{)}
          \PY{n}{nn\PYZus{}pred} \PY{o}{=} \PY{n}{nn\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The Performance of the new Neural Network using the Final Set of Features:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{nn\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The Performance of the new Neural Network using the Final Set of Features:
The out of sample performance on validation data is:
The accuracy is 0.853
The precision is 0.758
The recall is 0.816

    \end{Verbatim}

    Oh Wow! Just by tweaking the parameters a little we saw an even more 2\%
increase in Recall (going up to 81.6\%). No model previously has come
even close to this kind of recall. And even though there is some loss in
Precision and Accuracy is the same it shows that just changing
parameters slightly in a neural network can lead to changes in overall
model performance.

    \subsubsection{Neural Network Hyper Parameter
Tuning}\label{neural-network-hyper-parameter-tuning}

To get the best set of parameters we would have to do an exhaustive
search across the parameter spaces using many advanced algorithms
proposed in academic literature. Unforuntely there are lots of parameter
combinations and due to time constraints I will just do a small search
across a few of the more important parameters namely instead of trying
to implement more advanced academic approaches:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Batch size - the number of training samples a model sees at each step
\item
  Learnning Rate - in Stochastic gradient descent this is the rate at
  which weights are updated by the gradient to minimze the error
\item
  Hidden Neurons - The number of neurons in each of our layer (or
  weights)
\end{enumerate}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{neural\PYZus{}network\PYZus{}grid\PYZus{}search}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{input\PYZus{}len}\PY{p}{,} \PY{n}{e}\PY{p}{,} \PY{n}{batch}\PY{p}{,} \PY{n}{lr}\PY{p}{,} \PY{n}{neurons}\PY{p}{,} \PY{n}{seed}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} define the architecture for the simple feed forward network}
            \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{neurons}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{o}{=}\PY{n}{input\PYZus{}len}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.25}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n+nb}{int}\PY{p}{(}\PY{n}{neurons}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{relu}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.25}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n+nb}{int}\PY{p}{(}\PY{n}{neurons}\PY{o}{/}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{kernel\PYZus{}initializer}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{uniform}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sigmoid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Activation}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{sigmoid}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
            \PY{n}{optimizer} \PY{o}{=} \PY{n}{Adam}\PY{p}{(}\PY{n}{lr}\PY{o}{=}\PY{n}{lr}\PY{p}{)}
            \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{binary\PYZus{}crossentropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{n}{optimizer}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{accuracy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
            
            \PY{n}{early\PYZus{}stopping} \PY{o}{=} \PY{n}{EarlyStopping}\PY{p}{(}\PY{n}{monitor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{val\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{patience}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}
            \PY{n}{history} \PY{o}{=} \PY{n}{History}\PY{p}{(}\PY{p}{)}
            
            \PY{n}{nn\PYZus{}model} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}
                      \PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{n}{e}
                      \PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{n}{batch}
                      \PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}
                      \PY{p}{,} \PY{n}{validation\PYZus{}data} \PY{o}{=} \PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{)}
                      \PY{p}{,} \PY{n}{callbacks}\PY{o}{=}\PY{p}{[}\PY{n}{early\PYZus{}stopping}\PY{p}{,} \PY{n}{history}\PY{p}{]}
                      \PY{p}{,} \PY{n}{shuffle} \PY{o}{=} \PY{k+kc}{True}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{nn\PYZus{}model}\PY{p}{,} \PY{n}{nn\PYZus{}model}\PY{o}{.}\PY{n}{history} 
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}tuning the neural net with a few choices of parameters}
        \PY{n}{batch\PYZus{}sizes} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{32}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{,}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{256}\PY{p}{,}\PY{l+m+mi}{512}\PY{p}{]}
        \PY{n}{learning\PYZus{}rates} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.0001}\PY{p}{,} \PY{l+m+mf}{0.001}\PY{p}{,} \PY{l+m+mf}{0.01}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{neurons} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{256}\PY{p}{,}\PY{l+m+mi}{128}\PY{p}{,}\PY{l+m+mi}{64}\PY{p}{,}\PY{l+m+mi}{50}\PY{p}{,}\PY{l+m+mi}{26}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{]}
        \PY{n}{seed} \PY{o}{=} \PY{l+m+mi}{125758}
        
        \PY{n}{grid\PYZus{}search\PYZus{}results} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model\PYZus{}Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Batch Size}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Learning Rate}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Hidden Neurons Max}\PY{l+s+s1}{\PYZsq{}}
                                                    \PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Train\PYZus{}Acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid\PYZus{}Acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
        \PY{n}{i} \PY{o}{=} \PY{l+m+mi}{0}
        \PY{k}{for} \PY{n}{batch} \PY{o+ow}{in} \PY{n}{batch\PYZus{}sizes}\PY{p}{:}
            \PY{k}{for} \PY{n}{lr} \PY{o+ow}{in} \PY{n}{learning\PYZus{}rates}\PY{p}{:}
                \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{neurons}\PY{p}{:}
                    \PY{n}{nn\PYZus{}model}\PY{p}{,} \PY{n}{model\PYZus{}hist} \PY{o}{=} \PY{n}{neural\PYZus{}network\PYZus{}grid\PYZus{}search}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{batch}\PY{p}{,} \PY{n}{lr}\PY{p}{,} \PY{n}{n}\PY{p}{,} \PY{n}{seed}\PY{p}{)}
                    
                    \PY{n}{val\PYZus{}loss} \PY{o}{=} \PY{n}{model\PYZus{}hist}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{val\PYZus{}loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
                    \PY{n}{val\PYZus{}acc} \PY{o}{=} \PY{n}{model\PYZus{}hist}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{val\PYZus{}acc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
                    \PY{n}{loss} \PY{o}{=} \PY{n}{model\PYZus{}hist}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{loss}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
                    \PY{n}{acc} \PY{o}{=} \PY{n}{model\PYZus{}hist}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{acc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
        
                    \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{l+m+mi}{0}
                    \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{n}{i}
                    \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{batch}
                    \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{=} \PY{n}{lr}
                    \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{]} \PY{o}{=} \PY{n}{n}
                    \PY{c+c1}{\PYZsh{}grid\PYZus{}search\PYZus{}results.iloc[i,4] = loss}
                    \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]} \PY{o}{=} \PY{n}{acc}
                    \PY{c+c1}{\PYZsh{}grid\PYZus{}search\PYZus{}results.iloc[i,6] = val\PYZus{}loss}
                    \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{n}{i}\PY{p}{,}\PY{l+m+mi}{7}\PY{p}{]} \PY{o}{=} \PY{n}{val\PYZus{}acc}
        
        
                    \PY{n+nb}{print}\PY{p}{(}\PY{n}{i}\PY{p}{)}
                    \PY{n}{i} \PY{o}{=} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}
        
        \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{set\PYZus{}index}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Model\PYZus{}Number}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grid\PYZus{}search\PYZus{}results.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{index} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}
        \PY{n}{grid\PYZus{}search\PYZus{}results}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Valid\PYZus{}Acc}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{grid\PYZus{}search\PYZus{}results}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}nn\PYZus{}model, model\PYZus{}hist = neural\PYZus{}network\PYZus{}grid\PYZus{}search(x\PYZus{}train, y\PYZus{}train, x\PYZus{}train.shape[1], 25, 128, 0.01, 50, 167)}
\end{Verbatim}


    \section{b) Stacking}\label{b-stacking}

Stacking is a powerful technique where we split the train data into
smaller random chunks. Then train a model on another small subset of
data and use the parameters from that model to make predictions on
another completely disjoint subset of data. By stacking predictions from
1 model to another subset of data we can train using predictions as
features which can help us achieve better performance. The following
functions do stacking where train is split in two parts. Part A trains a
logistic regression and then Part B uses predictions from the log
regression model in Part A to train a random foresrt on Part B

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}196}]:} \PY{k}{def} \PY{n+nf}{train\PYZus{}stacked\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{stack\PYZus{}split\PYZus{}perc}\PY{p}{,} \PY{n}{split\PYZus{}perc}\PY{p}{)}\PY{p}{:}
              
              \PY{n}{standard\PYZus{}scaler} \PY{o}{=} \PY{n}{preprocessing}\PY{o}{.}\PY{n}{StandardScaler}\PY{p}{(}\PY{n}{with\PYZus{}mean}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{with\PYZus{}std}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                  
              \PY{n}{train\PYZus{}valid}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{split\PYZus{}perc}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{45}\PY{p}{)}
              \PY{n}{train}\PY{p}{,} \PY{n}{valid} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{train\PYZus{}valid}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{split\PYZus{}perc}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{45}\PY{p}{)}    
              \PY{n}{stack\PYZus{}one}\PY{p}{,} \PY{n}{stack\PYZus{}two} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{train}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{stack\PYZus{}split\PYZus{}perc}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{45}\PY{p}{)}    
              
              \PY{n}{x\PYZus{}stack\PYZus{}one} \PY{o}{=} \PY{n}{stack\PYZus{}one}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
              \PY{n}{x\PYZus{}stack\PYZus{}two} \PY{o}{=} \PY{n}{stack\PYZus{}two}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
              \PY{n}{x\PYZus{}valid} \PY{o}{=} \PY{n}{valid}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
              \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
              
              \PY{n}{x\PYZus{}stack\PYZus{}one} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}stack\PYZus{}one}\PY{p}{)}
              \PY{n}{x\PYZus{}stack\PYZus{}two} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}stack\PYZus{}two}\PY{p}{)}
              \PY{n}{x\PYZus{}valid} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
              \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
              
              \PY{n}{y\PYZus{}stack\PYZus{}one} \PY{o}{=} \PY{n}{stack\PYZus{}one}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{y\PYZus{}stack\PYZus{}two} \PY{o}{=} \PY{n}{stack\PYZus{}two}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{y\PYZus{}valid} \PY{o}{=} \PY{n}{valid}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
                  
              \PY{k}{return} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{x\PYZus{}stack\PYZus{}one}\PY{p}{,} \PY{n}{x\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{n}{y\PYZus{}stack\PYZus{}one}\PY{p}{,} \PY{n}{y\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}205}]:} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{x\PYZus{}stack\PYZus{}one}\PY{p}{,} \PY{n}{x\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{n}{y\PYZus{}stack\PYZus{}one}\PY{p}{,} \PY{n}{y\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}stacked\PYZus{}split}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,}\PY{l+m+mf}{0.3}\PY{p}{)}
          \PY{n}{stack\PYZus{}one\PYZus{}model}\PY{p}{,} \PY{n}{stack\PYZus{}train\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}stack\PYZus{}one}\PY{p}{,} \PY{n}{y\PYZus{}stack\PYZus{}one}\PY{p}{,} \PY{n}{x\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{c+c1}{\PYZsh{}stack\PYZus{}one\PYZus{}model, stack\PYZus{}train\PYZus{}preds = train\PYZus{}neural\PYZus{}network(x\PYZus{}stack\PYZus{}one, y\PYZus{}stack\PYZus{}one, x\PYZus{}stack\PYZus{}one.shape[1], 25, 128, 0.001)}
          \PY{n}{stack\PYZus{}valid\PYZus{}preds} \PY{o}{=} \PY{n}{stack\PYZus{}one\PYZus{}model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
          \PY{n}{stack\PYZus{}test\PYZus{}preds} \PY{o}{=} \PY{n}{stack\PYZus{}one\PYZus{}model}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
          \PY{n}{x\PYZus{}stack\PYZus{}two} \PY{o}{=}  \PY{n}{np}\PY{o}{.}\PY{n}{column\PYZus{}stack}\PY{p}{(}\PY{p}{[}\PY{n}{x\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{n}{stack\PYZus{}train\PYZus{}preds}\PY{p}{]}\PY{p}{)}
          \PY{n}{x\PYZus{}valid} \PY{o}{=}  \PY{n}{np}\PY{o}{.}\PY{n}{column\PYZus{}stack}\PY{p}{(}\PY{p}{[}\PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{stack\PYZus{}valid\PYZus{}preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
          \PY{n}{x\PYZus{}test} \PY{o}{=}  \PY{n}{np}\PY{o}{.}\PY{n}{column\PYZus{}stack}\PY{p}{(}\PY{p}{[}\PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{stack\PYZus{}test\PYZus{}preds}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{]}\PY{p}{)}
          \PY{n}{stacked\PYZus{}rf\PYZus{}model}\PY{p}{,} \PY{n}{stacked\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{n}{y\PYZus{}stack\PYZus{}two}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
\end{Verbatim}


    However, It seems like stacking doesn't improve model performance here.
The first model is a log regression and then a random forest uses its
predictions to make predictions using a second subset of data. But the
stacked ensemble doesn't seem to do better than an individual random
forest.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}209}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Performance of the Stacked Log Regressionm + Random Forest Model}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{stacked\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Performance of the Stacked Log Regressionm + Random Forest Model
The out of sample performance on validation data is:
The accuracy is 0.853
The precision is 0.773
The recall is 0.785

    \end{Verbatim}

    \section{c) Blending}\label{c-blending}

Finally I will try blending in the predictions of different models to
see if it helps with performance. Blending is simply taking a weighted
average of each of the indivudual model predictions. So for example we
can combine the log regression, random forest, and neural network
predictions in a weighted linear combination so that some model
predictions are weighted more heavily than others. Blending works when
we have many uncorrelated (or low correlated) models. The general idea
being that 1 model might be good at detecting particular trends while
another might be good at detecting other trends so their combined
ensemble might lead to overall improvements that neither of the two
models individually could achieve.

In this experiment I will just try a couple of combinations but
theoretically we can try all different combinations to see which one
performs best.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{nn\PYZus{}pred} \PY{o}{=} \PY{n}{nn\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
        \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
        \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}238}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Blending the Neural Net and Random Forest in 60/40}\PY{l+s+si}{\PYZpc{} r}\PY{l+s+s1}{atio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{blended\PYZus{}preds} \PY{o}{=} \PY{l+m+mf}{0.6}\PY{o}{*}\PY{n}{nn\PYZus{}pred}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{+} \PY{l+m+mf}{0.4}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{blended\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The out of sample performance on validation data is:
The accuracy is 0.856
The precision is 0.767
The recall is 0.809

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}246}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} All 3 \PYZhy{} Neural Network + Random Forest + Logisitic Regression}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Blending the Neural Net and Random Forestand Logistic Regression in 50/30/20}\PY{l+s+si}{\PYZpc{} r}\PY{l+s+s1}{atio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{blended\PYZus{}preds} \PY{o}{=} \PY{l+m+mf}{0.5}\PY{o}{*}\PY{n}{nn\PYZus{}pred}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{+} \PY{l+m+mf}{0.3}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{0.2}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{)}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{blended\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Blending the Neural Net and Random Forestand Logistic Regression in 60/40\% ratio
The out of sample performance on validation data is:
The accuracy is 0.856
The precision is 0.771
The recall is 0.801

    \end{Verbatim}

    From the above we can see that when we blend in all 3 models we actually
get a model that is superior than any of the ones individually. In this
case we were able to get marginally higher accuracy but also precision
and recall that were either the same or better than the individual
models. Although the differences are very small and it remains to be
seen if these will actually translate into measurable lift.

    \section{PART G - EVALUATION ON TEST
DATA}\label{part-g---evaluation-on-test-data}

To summarize here are the results of all the models we tried (Note:
results changed a little due to random seeding for some) including
measured against the baseline. All told, our final model does much
better than the baseline seeing a 20\% improvement in Recall and a 5\%
improvement in Precision and Accuracy.

But so far all feature engineering, training and tuning and ensembling
has been done on a validation data set split. Now that we have a model
ready we are ready to see how goood the model actually performs when
tested against completely new hidden data. For this reason, the final
ensemble model which is the best model will be evaluated on new test
data that was originally held out prior to training. This test data
comprises 30\% of all the data that was kept after data cleaning
randomly sampled.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}250}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} need to modify function slightly so it returns us a test dataframe too.}
          \PY{k}{def} \PY{n+nf}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{split\PYZus{}perc}\PY{p}{)}\PY{p}{:}
              
              \PY{c+c1}{\PYZsh{}train\PYZus{}valid = data[data[\PYZsq{}ds\PYZsq{}] \PYZlt{}= date\PYZus{}cutoff]}
              \PY{c+c1}{\PYZsh{}test = data[data[\PYZsq{}ds\PYZsq{}] \PYZgt{} date\PYZus{}cutoff] }
              
              \PY{n}{standard\PYZus{}scaler} \PY{o}{=} \PY{n}{preprocessing}\PY{o}{.}\PY{n}{StandardScaler}\PY{p}{(}\PY{n}{with\PYZus{}mean}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{with\PYZus{}std}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
              
              \PY{n}{train\PYZus{}valid}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{split\PYZus{}perc}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{45}\PY{p}{)}
              \PY{n}{train}\PY{p}{,} \PY{n}{valid} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{train\PYZus{}valid}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{n}{split\PYZus{}perc}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{45}\PY{p}{)}
              
              \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
              \PY{n}{x\PYZus{}valid} \PY{o}{=} \PY{n}{valid}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
              \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{:}\PY{p}{]}
              
              \PY{n}{x\PYZus{}train} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{)}
              \PY{n}{x\PYZus{}valid} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}valid}\PY{p}{)}
              \PY{n}{x\PYZus{}test} \PY{o}{=} \PY{n}{standard\PYZus{}scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
              
              \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{y\PYZus{}valid} \PY{o}{=} \PY{n}{valid}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
              \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
                  
              \PY{k}{return} \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{test}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}251}]:} \PY{c+c1}{\PYZsh{}\PYZsh{} All 3 \PYZhy{} Neural Network + Random Forest + Logisitic Regression}
          \PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}valid}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{test} \PY{o}{=} \PY{n}{train\PYZus{}valid\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{airbnb\PYZus{}derived\PYZus{}features\PYZus{}data\PYZus{}v4}\PY{p}{,} \PY{l+m+mf}{0.3}\PY{p}{)}
          \PY{n}{nn\PYZus{}pred} \PY{o}{=} \PY{n}{nn\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{x\PYZus{}test}\PY{p}{)}
          \PY{n}{rf\PYZus{}model}\PY{p}{,} \PY{n}{rf\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}random\PYZus{}forest}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{log\PYZus{}reg\PYZus{}model}\PY{p}{,} \PY{n}{log\PYZus{}preds} \PY{o}{=} \PY{n}{train\PYZus{}logistic\PYZus{}regression}\PY{p}{(}\PY{n}{x\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{x\PYZus{}test}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Blending the Neural Net and Random Forestand Logistic Regression in 50/30/20}\PY{l+s+si}{\PYZpc{} r}\PY{l+s+s1}{atio}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{test\PYZus{}blended\PYZus{}preds} \PY{o}{=} \PY{l+m+mf}{0.5}\PY{o}{*}\PY{n}{nn\PYZus{}pred}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{+} \PY{l+m+mf}{0.3}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{rf\PYZus{}preds}\PY{p}{)} \PY{o}{+} \PY{l+m+mf}{0.2}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{log\PYZus{}preds}\PY{p}{)}
          \PY{n}{test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}predictions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{test\PYZus{}blended\PYZus{}preds}
          \PY{n}{a}\PY{p}{,}\PY{n}{p}\PY{p}{,}\PY{n}{r} \PY{o}{=} \PY{n}{print\PYZus{}model\PYZus{}performance}\PY{p}{(}\PY{n}{test\PYZus{}blended\PYZus{}preds}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Blending the Neural Net and Random Forest and Logistic Regression in 60/40\% ratio
The out of sample performance on validation data is:
The accuracy is 0.855
The precision is 0.780
The recall is 0.783

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}281}]:} \PY{n}{test}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}final.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    The final blended model performs similarly on the test set indiccating
no major overfitting of data (although recall does drop slightly).
Either way this model is still at least 5\% better than the baseline we
built in the beginning.

    \subsection{Model Performance on Sub
Cohorts}\label{model-performance-on-sub-cohorts}

To better understand model performance I break up model performance over
different cohorts to see if the model performs better in some cohorts vs
others

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}374}]:} \PY{k}{def} \PY{n+nf}{accuracy}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{:}
              \PY{k}{if} \PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1} \PY{o+ow}{and} \PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}predictions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{\PYZgt{}}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)} \PY{o+ow}{or} \PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}requested}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0} \PY{o+ow}{and} \PY{n}{x}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model\PYZus{}predictions}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{\PYZlt{}}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{:}
                  \PY{k}{return} \PY{l+m+mi}{1}
              \PY{k}{else}\PY{p}{:}
                  \PY{k}{return} \PY{l+m+mi}{0}
          
          \PY{n}{cohort\PYZus{}data} \PY{o}{=} \PY{n}{test}\PY{o}{.}\PY{n}{assign}\PY{p}{(}\PY{n}{correct\PYZus{}pred}\PY{o}{=}\PY{n}{test}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{accuracy}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}362}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{n}{feature}\PY{p}{)}\PY{p}{:}
              \PY{n}{cohorts} \PY{o}{=} \PY{n}{cohort\PYZus{}data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{n}{feature}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{correct\PYZus{}pred}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{o}{/}\PY{n}{cohort\PYZus{}data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{p}{[}\PY{n}{feature}\PY{p}{]}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{correct\PYZus{}pred}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{cohorts}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{n}{feature}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of Model when brekaing down by: }\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{feature}\PY{p}{)}\PY{p}{)}
              \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    It seems like (ignore outliers cohorts with only a few points taking
accuracy up to 1): 1) non holiday seasoons like spring and fall are the
toughest for the model to predict. 2) the more the capacity the harder
it gets to predict correctly 3) listings that just had a booking (months
since Last booking = 0) are harder to predict

These insights give us clues as to where the model can be improved. In
particular the part about recent booked listings being more difficult to
predict correctly is insightful because it can force us to look for more
data points for listings that just had a booking

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}324}]:} \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{month\PYZus{}of\PYZus{}year}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_100_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}326}]:} \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}person\PYZus{}capacity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_101_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}329}]:} \PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kdt\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{around}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kdt\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kdt\PYZus{}score}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_102_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}375}]:} \PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{floor}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{l+m+mi}{100}\PY{p}{)}
          \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}effective\PYZus{}daily\PYZus{}price}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_103_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}340}]:} \PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{months\PYZus{}since\PYZus{}last\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{floor}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{days\PYZus{}since\PYZus{}last\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{l+m+mi}{30}\PY{p}{)}
          \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{months\PYZus{}since\PYZus{}last\PYZus{}booking}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_104_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}345}]:} \PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}total\PYZus{}overall\PYZus{}rating}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{floor}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}total\PYZus{}overall\PYZus{}rating}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{l+m+mi}{10}\PY{p}{)}
          \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{m\PYZus{}total\PYZus{}overall\PYZus{}rating}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_105_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}365}]:} \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}is\PYZus{}instant\PYZus{}bookable}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_106_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}368}]:} \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}market\PYZus{}San Francisco}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_107_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}369}]:} \PY{n}{plot\PYZus{}cohort\PYZus{}accuracy\PYZus{}continuous}\PY{p}{(}\PY{n}{cohort\PYZus{}data}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{dim\PYZus{}market\PYZus{}Paris}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_108_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \section{Conclusion}\label{conclusion}

\subsection{Summary}\label{summary}

In this project, I used Airbnb Data to predict whether a listing on a
given day would be booked 30 days into the future or not. The features
initially provided did a poor job beating a simple baseline that just
looked at whether a listing was booked or not in the last available
period. Simple Logistic Regression with Regularization and a Random
Forest were trained to help make predictions and the evaluation metric
used was Accuracy along with Precision and Recall. Train, Validation and
Test sets were randomly created from the data for evaluation purpose
with 50\% train, 20\% validation and 30\% test data.

However, with feature enginering I devised a series of features that
indicated historical booking status of a listing in the recent past, and
a listing's historical average price and demand in the area. These
features helped improve the model performance by at least 5\% in
accuracy and precision and approximately 20\% in Recall easily beating
the baseline.

In addition, more advanced algorithms and ensembling techniques like
neural nets and blending/stacking weres used which might have improved
performance by a slight margin as well.

Finally model was evaluated on out of seen test data after all parameter
tuning and feature engineering was done. The final performance on out of
sample test data was very similar to validation accuracy (approximately
85\%) indicating that overfitting on validation data had not occured and
the model could indeed be generalized and put in production.

The results of all the models are again summarized below for reference.

    \subsection{Product Recommendations for Using
Model}\label{product-recommendations-for-using-model}

If we have a good model that can predict whether a listing will be
booked 30 days in advance or not then we can leverage this information
proactively to make product enhancements that help drive and improve the
user experience for both guests and hosts. Here are some specific ways
new product features could be launched using the model predictions:

\subsubsection{To improve the User
Experience}\label{to-improve-the-user-experience}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \texttt{Introduce\ Urgency\ Messaging\ on\ Listing\ Cards/Pages:} If a
  listing is expected to be booked then we can have a special message on
  the listing card on the browse or listing page that basically tells
  the user that this listing is about to be booked. This will create
  urgency for users who are on the fence about booking
\item
  \texttt{Introduce\ Urgency\ Messaging\ through\ Email/Push}: Same as
  above but this time if a listing is expected to be booked then we send
  an email and push notification to users who saw that listing informing
  them about the listing about to be booked.
\end{enumerate}

\subsubsection{To improve the Host
Experience}\label{to-improve-the-host-experience}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \texttt{Encourage\ Hosts\ to\ Reduce\ Prices\ to\ Drive\ Bookings}: If
  a listing is expected to not be booked then hosts can be informed
  about changing prices to encourage people to book. If we recall from
  the analysis on feature importance, price changes were highly
  predictive of whether a listing will be booked.
\item
  \texttt{Encourage\ Hosts\ to\ Increase\ Availability/Re\ List\ their\ Apartments/Homes}:
  If a marketplace is showing strong increase in bookings likely to be
  made in the next month using the model predictions, then we can
  esentially email hosts that are inactive or have their apartments
  unavailable to increase availability and list their apartments online
  as they are more likely to be booked. This leads to more bookings for
  the host.
\end{enumerate}

    \subsection{Other Modeling Ideas using this
Dataset}\label{other-modeling-ideas-using-this-dataset}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
